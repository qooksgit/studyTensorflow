{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from tensorflow.python.platform import gfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<absl.flags._flagvalues.FlagHolder at 0x13a975d10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'model_dir', '/Users/i550012/study/LLM/tensorflow/imagenet',\n",
    "    \"\"\"Path to classify_image_graph_def.pb, \"\"\"\n",
    "    \"\"\"imagenet_synset_to_human_label_map.txt, and \"\"\"\n",
    "    \"\"\"imagenet_2012_challenge_label_map_proto.pbtxt.\"\"\")\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeLookup(object):\n",
    "  \"\"\"Converts integer node ID's to human readable labels.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               label_lookup_path=None,\n",
    "               uid_lookup_path=None):\n",
    "    if not label_lookup_path:\n",
    "      label_lookup_path = os.path.join(\n",
    "          FLAGS.model_dir, 'imagenet_2012_challenge_label_map_proto.pbtxt')\n",
    "    if not uid_lookup_path:\n",
    "      uid_lookup_path = os.path.join(\n",
    "          FLAGS.model_dir, 'imagenet_synset_to_human_label_map.txt')\n",
    "    self.node_lookup = self.load(label_lookup_path, uid_lookup_path)\n",
    "\n",
    "  def load(self, label_lookup_path, uid_lookup_path):\n",
    "    \"\"\"Loads a human readable English name for each softmax node.\n",
    "\n",
    "    Args:\n",
    "      label_lookup_path: string UID to integer node ID.\n",
    "      uid_lookup_path: string UID to human-readable string.\n",
    "\n",
    "    Returns:\n",
    "      dict from integer node ID to human-readable string.\n",
    "    \"\"\"\n",
    "    if not gfile.Exists(uid_lookup_path):\n",
    "      tf.logging.fatal('File does not exist %s', uid_lookup_path)\n",
    "    if not gfile.Exists(label_lookup_path):\n",
    "      tf.logging.fatal('File does not exist %s', label_lookup_path)\n",
    "\n",
    "    # Loads mapping from string UID to human-readable string\n",
    "    proto_as_ascii_lines = gfile.GFile(uid_lookup_path).readlines()\n",
    "    uid_to_human = {}\n",
    "    p = re.compile(r'[n\\d]*[ \\S,]*')\n",
    "    for line in proto_as_ascii_lines:\n",
    "      parsed_items = p.findall(line)\n",
    "      uid = parsed_items[0]\n",
    "      human_string = parsed_items[2]\n",
    "      uid_to_human[uid] = human_string\n",
    "\n",
    "    # Loads mapping from string UID to integer node ID.\n",
    "    node_id_to_uid = {}\n",
    "    proto_as_ascii = gfile.GFile(label_lookup_path).readlines()\n",
    "    for line in proto_as_ascii:\n",
    "      if line.startswith('  target_class:'):\n",
    "        target_class = int(line.split(': ')[1])\n",
    "      if line.startswith('  target_class_string:'):\n",
    "        target_class_string = line.split(': ')[1]\n",
    "        node_id_to_uid[target_class] = target_class_string[1:-2]\n",
    "\n",
    "    # Loads the final mapping of integer node ID to human-readable string\n",
    "    node_id_to_name = {}\n",
    "    for key, val in node_id_to_uid.items():\n",
    "      if val not in uid_to_human:\n",
    "        tf.logging.fatal('Failed to locate: %s', val)\n",
    "      name = uid_to_human[val]\n",
    "      node_id_to_name[key] = name\n",
    "\n",
    "    return node_id_to_name\n",
    "\n",
    "  def id_to_string(self, node_id):\n",
    "    if node_id not in self.node_lookup:\n",
    "      return ''\n",
    "    return self.node_lookup[node_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'imagenet'\n",
    "graph_path = os.path.join(model_path, 'classify_image_graph_def.pb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/nl/yn0d4tg1107g2jk38nj1hc740000gn/T/ipykernel_28257/3929633588.py:1: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "WARNING:tensorflow:From /var/folders/nl/yn0d4tg1107g2jk38nj1hc740000gn/T/ipykernel_28257/3929633588.py:2: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 05:28:57.863998: W tensorflow/core/framework/op_def_util.cc:357] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().\n"
     ]
    }
   ],
   "source": [
    "with tf.gfile.FastGFile(graph_path, 'rb') as graphFile:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(graphFile.read())\n",
    "    _ = tf.import_graph_def(graph_def, name='Imagenet')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/nl/yn0d4tg1107g2jk38nj1hc740000gn/T/ipykernel_28257/3321593787.py:1: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca (89.11%)\n",
      "indri, indris, Indri indri, Indri brevicaudatus (0.78%)\n",
      "lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens (0.30%)\n",
      "custard apple (0.15%)\n",
      "earthstar (0.12%)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as session:\n",
    "    file_writer = tf.summary.FileWriter('logs', session.graph)\n",
    "    output_tensor = session.graph.get_tensor_by_name('Imagenet/softmax:0')\n",
    "    image_name = 'imagenet/cropped_panda.jpg'\n",
    "    image_data = tf.gfile.FastGFile(image_name, 'rb').read()\n",
    "    imput_tensor_name_data = {'Imagenet/DecodeJpeg/contents:0':image_data}\n",
    "    predictions = session.run(output_tensor, imput_tensor_name_data)\n",
    "    predictions = np.squeeze(predictions)\n",
    "    top_predictions = predictions.argsort()[-5:][::-1]\n",
    "    node_lookup = NodeLookup()\n",
    "    for predict in top_predictions:\n",
    "        percentage = predictions[predict]*100\n",
    "        human_string = node_lookup.id_to_string(predict)\n",
    "        print('%s (%.2f%%)' % (human_string, percentage))\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
