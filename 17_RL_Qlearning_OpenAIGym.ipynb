{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "import numpy as np\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i550012/virtualenv/tensorflow1/lib/python3.7/site-packages/gym/envs/registration.py:556: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  f\"The environment {id} is out of date. You should consider \"\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0', render_mode=\"rgb_array\")\n",
    "print(env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-4.8, 4.8), [-0.5, 0.5], (-0.41887903, 0.41887903), [-0.8726646259971648, 0.8726646259971648]]\n"
     ]
    }
   ],
   "source": [
    "NUM_BUCKETS = (1,1,6,3)\n",
    "NUM_ACTIONS = env.action_space.n\n",
    "STATE_BOUNDS = list(zip(env.observation_space.low,env.observation_space.high))\n",
    "STATE_BOUNDS[1] = [-0.5,0.5]\n",
    "STATE_BOUNDS[3] = [-math.radians(50),math.radians(50)]\n",
    "print(STATE_BOUNDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = np.zeros(NUM_BUCKETS+ (NUM_ACTIONS,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 6, 3, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPLORE_RATE_MIN = 0.01\n",
    "LEARNING_RATE_MIN = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_explore_rate(t):\n",
    "    return max(EXPLORE_RATE_MIN,min(1,1.0 - math.log10((t+1)/25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learning_rate(t):\n",
    "    return max(LEARNING_RATE_MIN,min(1,1.0 - math.log10((t+1)/25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state, explore_rate):\n",
    "    if random.random() < explore_rate:\n",
    "        action = env.action_space.sample()\n",
    "    else:\n",
    "        action = np.argmax(q_table[state])\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_bucket(state):\n",
    "    bucket_indices = []\n",
    "    for i in range(len(state)):\n",
    "        if state[i] <= STATE_BOUNDS[i][0]:\n",
    "            bucket_index = 0\n",
    "        elif state[i] >= STATE_BOUNDS[i][1]:\n",
    "            bucket_index = NUM_BUCKETS[i] - 1\n",
    "        else: \n",
    "            bound_width = STATE_BOUNDS[i][1] - STATE_BOUNDS[i][0]\n",
    "            offset = (NUM_BUCKETS[i]-1)*STATE_BOUNDS[i][0]/bound_width\n",
    "            scaling = (NUM_BUCKETS[i]-1)/bound_width\n",
    "            bucket_index = int(round(scaling*state[i]-offset))\n",
    "        bucket_indices.append(bucket_index)\n",
    "    return tuple(bucket_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate():\n",
    "    learning_rate = get_learning_rate(0)\n",
    "    explore_rate = get_explore_rate(0)\n",
    "    discount_factor = 0.99\n",
    "    num_streaks = 0\n",
    "    \n",
    "    for episode in range(1000):\n",
    "        observ = env.reset()\n",
    "        state_0 = state_to_bucket(observ[0])\n",
    "        for t in range(250):\n",
    "            env.render()\n",
    "            action = select_action(state_0,explore_rate)\n",
    "            observ, reward, done, _,_ = env.step(action)\n",
    "            state = state_to_bucket(observ)\n",
    "            best_q = np.amax(q_table[state])\n",
    "            q_table[state_0 + (action,)] += learning_rate*(reward + discount_factor*(best_q) - q_table[state_0 + (action,)])\n",
    "            state_0 = state\n",
    "\n",
    "            if done:\n",
    "                print(\"Episode %d, t = %d, action = %d, state = %s, reward = %f\" % (episode,t,action,state,reward))\n",
    "                print(\"\\t BestQ: %f, Explore rate: %f, Learning rate: %f, Streaks: %d\" % (best_q,explore_rate,learning_rate, num_streaks))\n",
    "                print(\"Episode %d finished after %f time steps\" % (episode,t))\n",
    "                if t >= 199:\n",
    "                    num_streaks += 1\n",
    "                else:\n",
    "                    num_streaks = 0\n",
    "                break\n",
    "        if num_streaks > 120:\n",
    "            break\n",
    "        explore_rate = get_explore_rate(episode)\n",
    "        learning_rate = get_learning_rate(episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, t = 14, action = 1, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 62.567223, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 0 finished after 14.000000 time steps\n",
      "Episode 1, t = 8, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 57.689676, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 1 finished after 8.000000 time steps\n",
      "Episode 2, t = 10, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 58.112779, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 2 finished after 10.000000 time steps\n",
      "Episode 3, t = 17, action = 1, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 62.941551, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 3 finished after 17.000000 time steps\n",
      "Episode 4, t = 19, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 59.356871, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 4 finished after 19.000000 time steps\n",
      "Episode 5, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 59.763303, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 5 finished after 19.000000 time steps\n",
      "Episode 6, t = 16, action = 1, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 63.312135, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 6 finished after 16.000000 time steps\n",
      "Episode 7, t = 10, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 60.165670, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 7 finished after 10.000000 time steps\n",
      "Episode 8, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 60.958373, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 8 finished after 18.000000 time steps\n",
      "Episode 9, t = 18, action = 1, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 64.042224, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 9 finished after 18.000000 time steps\n",
      "Episode 10, t = 12, action = 1, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 64.401802, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 10 finished after 12.000000 time steps\n",
      "Episode 11, t = 43, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 62.117948, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 11 finished after 43.000000 time steps\n",
      "Episode 12, t = 12, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 62.496769, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 12 finished after 12.000000 time steps\n",
      "Episode 13, t = 22, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 63.243083, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 13 finished after 22.000000 time steps\n",
      "Episode 14, t = 52, action = 0, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 65.110206, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 14 finished after 52.000000 time steps\n",
      "Episode 15, t = 13, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 63.974546, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 15 finished after 13.000000 time steps\n",
      "Episode 16, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 64.334800, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 16 finished after 16.000000 time steps\n",
      "Episode 17, t = 24, action = 1, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 65.459104, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 17 finished after 24.000000 time steps\n",
      "Episode 18, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 65.044538, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 18 finished after 16.000000 time steps\n",
      "Episode 19, t = 9, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 65.394092, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 19 finished after 9.000000 time steps\n",
      "Episode 20, t = 17, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 65.740151, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 20 finished after 17.000000 time steps\n",
      "Episode 21, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 66.421922, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 21 finished after 18.000000 time steps\n",
      "Episode 22, t = 10, action = 0, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 65.804513, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 22 finished after 10.000000 time steps\n",
      "Episode 23, t = 11, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 66.757703, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 23 finished after 11.000000 time steps\n",
      "Episode 24, t = 29, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 67.419225, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 24 finished after 29.000000 time steps\n",
      "Episode 25, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 67.745033, Explore rate: 1.000000, Learning rate: 1.000000, Streaks: 0\n",
      "Episode 25 finished after 16.000000 time steps\n",
      "Episode 26, t = 41, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 68.067582, Explore rate: 0.982967, Learning rate: 0.982967, Streaks: 0\n",
      "Episode 26 finished after 41.000000 time steps\n",
      "Episode 27, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 92.835309, Explore rate: 0.966576, Learning rate: 0.966576, Streaks: 0\n",
      "Episode 27 finished after 22.000000 time steps\n",
      "Episode 28, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 92.835309, Explore rate: 0.950782, Learning rate: 0.950782, Streaks: 0\n",
      "Episode 28 finished after 18.000000 time steps\n",
      "Episode 29, t = 33, action = 1, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 66.463182, Explore rate: 0.935542, Learning rate: 0.935542, Streaks: 0\n",
      "Episode 29 finished after 33.000000 time steps\n",
      "Episode 30, t = 54, action = 0, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 66.734476, Explore rate: 0.920819, Learning rate: 0.920819, Streaks: 0\n",
      "Episode 30 finished after 54.000000 time steps\n",
      "Episode 31, t = 11, action = 1, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 67.019310, Explore rate: 0.906578, Learning rate: 0.906578, Streaks: 0\n",
      "Episode 31 finished after 11.000000 time steps\n",
      "Episode 32, t = 62, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.876502, Explore rate: 0.892790, Learning rate: 0.892790, Streaks: 0\n",
      "Episode 32 finished after 62.000000 time steps\n",
      "Episode 33, t = 14, action = 1, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 67.291696, Explore rate: 0.879426, Learning rate: 0.879426, Streaks: 0\n",
      "Episode 33 finished after 14.000000 time steps\n",
      "Episode 34, t = 16, action = 1, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 67.860254, Explore rate: 0.866461, Learning rate: 0.866461, Streaks: 0\n",
      "Episode 34 finished after 16.000000 time steps\n",
      "Episode 35, t = 79, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.877557, Explore rate: 0.853872, Learning rate: 0.853872, Streaks: 0\n",
      "Episode 35 finished after 79.000000 time steps\n",
      "Episode 36, t = 28, action = 0, state = (0, 0, 1, 1), reward = 1.000000\n",
      "\t BestQ: 99.208419, Explore rate: 0.841638, Learning rate: 0.841638, Streaks: 0\n",
      "Episode 36 finished after 28.000000 time steps\n",
      "Episode 37, t = 24, action = 1, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 98.440243, Explore rate: 0.829738, Learning rate: 0.829738, Streaks: 0\n",
      "Episode 37 finished after 24.000000 time steps\n",
      "Episode 38, t = 13, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.935877, Explore rate: 0.818156, Learning rate: 0.818156, Streaks: 0\n",
      "Episode 38 finished after 13.000000 time steps\n",
      "Episode 39, t = 12, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.936402, Explore rate: 0.806875, Learning rate: 0.806875, Streaks: 0\n",
      "Episode 39 finished after 12.000000 time steps\n",
      "Episode 40, t = 12, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.936915, Explore rate: 0.795880, Learning rate: 0.795880, Streaks: 0\n",
      "Episode 40 finished after 12.000000 time steps\n",
      "Episode 41, t = 24, action = 0, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 99.049596, Explore rate: 0.785156, Learning rate: 0.785156, Streaks: 0\n",
      "Episode 41 finished after 24.000000 time steps\n",
      "Episode 42, t = 8, action = 0, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 99.057058, Explore rate: 0.774691, Learning rate: 0.774691, Streaks: 0\n",
      "Episode 42 finished after 8.000000 time steps\n",
      "Episode 43, t = 17, action = 1, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 99.064363, Explore rate: 0.764472, Learning rate: 0.764472, Streaks: 0\n",
      "Episode 43 finished after 17.000000 time steps\n",
      "Episode 44, t = 28, action = 0, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 99.064363, Explore rate: 0.754487, Learning rate: 0.754487, Streaks: 0\n",
      "Episode 44 finished after 28.000000 time steps\n",
      "Episode 45, t = 36, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.945870, Explore rate: 0.744727, Learning rate: 0.744727, Streaks: 0\n",
      "Episode 45 finished after 36.000000 time steps\n",
      "Episode 46, t = 60, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.945870, Explore rate: 0.735182, Learning rate: 0.735182, Streaks: 0\n",
      "Episode 46 finished after 60.000000 time steps\n",
      "Episode 47, t = 18, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.946268, Explore rate: 0.725842, Learning rate: 0.725842, Streaks: 0\n",
      "Episode 47 finished after 18.000000 time steps\n",
      "Episode 48, t = 15, action = 0, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 99.073347, Explore rate: 0.716699, Learning rate: 0.716699, Streaks: 0\n",
      "Episode 48 finished after 15.000000 time steps\n",
      "Episode 49, t = 11, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.946658, Explore rate: 0.707744, Learning rate: 0.707744, Streaks: 0\n",
      "Episode 49 finished after 11.000000 time steps\n",
      "Episode 50, t = 36, action = 0, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 99.079443, Explore rate: 0.698970, Learning rate: 0.698970, Streaks: 0\n",
      "Episode 50 finished after 36.000000 time steps\n",
      "Episode 51, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.947026, Explore rate: 0.690370, Learning rate: 0.690370, Streaks: 0\n",
      "Episode 51 finished after 18.000000 time steps\n",
      "Episode 52, t = 9, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.947026, Explore rate: 0.681937, Learning rate: 0.681937, Streaks: 0\n",
      "Episode 52 finished after 9.000000 time steps\n",
      "Episode 53, t = 36, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.947742, Explore rate: 0.673664, Learning rate: 0.673664, Streaks: 0\n",
      "Episode 53 finished after 36.000000 time steps\n",
      "Episode 54, t = 66, action = 1, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 99.091962, Explore rate: 0.665546, Learning rate: 0.665546, Streaks: 0\n",
      "Episode 54 finished after 66.000000 time steps\n",
      "Episode 55, t = 18, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.948094, Explore rate: 0.657577, Learning rate: 0.657577, Streaks: 0\n",
      "Episode 55 finished after 18.000000 time steps\n",
      "Episode 56, t = 13, action = 0, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 99.097944, Explore rate: 0.649752, Learning rate: 0.649752, Streaks: 0\n",
      "Episode 56 finished after 13.000000 time steps\n",
      "Episode 57, t = 67, action = 1, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 99.101710, Explore rate: 0.642065, Learning rate: 0.642065, Streaks: 0\n",
      "Episode 57 finished after 67.000000 time steps\n",
      "Episode 58, t = 19, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.949277, Explore rate: 0.634512, Learning rate: 0.634512, Streaks: 0\n",
      "Episode 58 finished after 19.000000 time steps\n",
      "Episode 59, t = 44, action = 1, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 99.105939, Explore rate: 0.627088, Learning rate: 0.627088, Streaks: 0\n",
      "Episode 59 finished after 44.000000 time steps\n",
      "Episode 60, t = 77, action = 1, state = (0, 0, 4, 1), reward = 1.000000\n",
      "\t BestQ: 99.992232, Explore rate: 0.619789, Learning rate: 0.619789, Streaks: 0\n",
      "Episode 60 finished after 77.000000 time steps\n",
      "Episode 61, t = 9, action = 1, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 99.111545, Explore rate: 0.612610, Learning rate: 0.612610, Streaks: 0\n",
      "Episode 61 finished after 9.000000 time steps\n",
      "Episode 62, t = 15, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.976189, Explore rate: 0.605548, Learning rate: 0.605548, Streaks: 0\n",
      "Episode 62 finished after 15.000000 time steps\n",
      "Episode 63, t = 11, action = 0, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 99.116988, Explore rate: 0.598599, Learning rate: 0.598599, Streaks: 0\n",
      "Episode 63 finished after 11.000000 time steps\n",
      "Episode 64, t = 15, action = 1, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 99.116988, Explore rate: 0.591760, Learning rate: 0.591760, Streaks: 0\n",
      "Episode 64 finished after 15.000000 time steps\n",
      "Episode 65, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.976334, Explore rate: 0.585027, Learning rate: 0.585027, Streaks: 0\n",
      "Episode 65 finished after 22.000000 time steps\n",
      "Episode 66, t = 34, action = 1, state = (0, 0, 4, 1), reward = 1.000000\n",
      "\t BestQ: 99.992232, Explore rate: 0.578396, Learning rate: 0.578396, Streaks: 0\n",
      "Episode 66 finished after 34.000000 time steps\n",
      "Episode 67, t = 29, action = 1, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 99.122213, Explore rate: 0.571865, Learning rate: 0.571865, Streaks: 0\n",
      "Episode 67 finished after 29.000000 time steps\n",
      "Episode 68, t = 10, action = 1, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 99.127233, Explore rate: 0.565431, Learning rate: 0.565431, Streaks: 0\n",
      "Episode 68 finished after 10.000000 time steps\n",
      "Episode 69, t = 61, action = 0, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 99.127233, Explore rate: 0.559091, Learning rate: 0.559091, Streaks: 0\n",
      "Episode 69 finished after 61.000000 time steps\n",
      "Episode 70, t = 15, action = 1, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 99.127233, Explore rate: 0.552842, Learning rate: 0.552842, Streaks: 0\n",
      "Episode 70 finished after 15.000000 time steps\n",
      "Episode 71, t = 29, action = 1, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 99.132004, Explore rate: 0.546682, Learning rate: 0.546682, Streaks: 0\n",
      "Episode 71 finished after 29.000000 time steps\n",
      "Episode 72, t = 21, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.985689, Explore rate: 0.540608, Learning rate: 0.540608, Streaks: 0\n",
      "Episode 72 finished after 21.000000 time steps\n",
      "Episode 73, t = 98, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.989139, Explore rate: 0.534617, Learning rate: 0.534617, Streaks: 0\n",
      "Episode 73 finished after 98.000000 time steps\n",
      "Episode 74, t = 105, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.989197, Explore rate: 0.528708, Learning rate: 0.528708, Streaks: 0\n",
      "Episode 74 finished after 105.000000 time steps\n",
      "Episode 75, t = 25, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.991615, Explore rate: 0.522879, Learning rate: 0.522879, Streaks: 0\n",
      "Episode 75 finished after 25.000000 time steps\n",
      "Episode 76, t = 63, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992873, Explore rate: 0.517126, Learning rate: 0.517126, Streaks: 0\n",
      "Episode 76 finished after 63.000000 time steps\n",
      "Episode 77, t = 13, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992873, Explore rate: 0.511449, Learning rate: 0.511449, Streaks: 0\n",
      "Episode 77 finished after 13.000000 time steps\n",
      "Episode 78, t = 9, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992873, Explore rate: 0.505845, Learning rate: 0.505845, Streaks: 0\n",
      "Episode 78 finished after 9.000000 time steps\n",
      "Episode 79, t = 53, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992147, Explore rate: 0.500313, Learning rate: 0.500313, Streaks: 0\n",
      "Episode 79 finished after 53.000000 time steps\n",
      "Episode 80, t = 9, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992186, Explore rate: 0.494850, Learning rate: 0.494850, Streaks: 0\n",
      "Episode 80 finished after 9.000000 time steps\n",
      "Episode 81, t = 18, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992225, Explore rate: 0.489455, Learning rate: 0.489455, Streaks: 0\n",
      "Episode 81 finished after 18.000000 time steps\n",
      "Episode 82, t = 13, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992225, Explore rate: 0.484126, Learning rate: 0.484126, Streaks: 0\n",
      "Episode 82 finished after 13.000000 time steps\n",
      "Episode 83, t = 23, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992275, Explore rate: 0.478862, Learning rate: 0.478862, Streaks: 0\n",
      "Episode 83 finished after 23.000000 time steps\n",
      "Episode 84, t = 15, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992348, Explore rate: 0.473661, Learning rate: 0.473661, Streaks: 0\n",
      "Episode 84 finished after 15.000000 time steps\n",
      "Episode 85, t = 32, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992420, Explore rate: 0.468521, Learning rate: 0.468521, Streaks: 0\n",
      "Episode 85 finished after 32.000000 time steps\n",
      "Episode 86, t = 8, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992420, Explore rate: 0.463442, Learning rate: 0.463442, Streaks: 0\n",
      "Episode 86 finished after 8.000000 time steps\n",
      "Episode 87, t = 29, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992524, Explore rate: 0.458421, Learning rate: 0.458421, Streaks: 0\n",
      "Episode 87 finished after 29.000000 time steps\n",
      "Episode 88, t = 12, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992559, Explore rate: 0.453457, Learning rate: 0.453457, Streaks: 0\n",
      "Episode 88 finished after 12.000000 time steps\n",
      "Episode 89, t = 12, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992592, Explore rate: 0.448550, Learning rate: 0.448550, Streaks: 0\n",
      "Episode 89 finished after 12.000000 time steps\n",
      "Episode 90, t = 24, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992625, Explore rate: 0.443697, Learning rate: 0.443697, Streaks: 0\n",
      "Episode 90 finished after 24.000000 time steps\n",
      "Episode 91, t = 10, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992658, Explore rate: 0.438899, Learning rate: 0.438899, Streaks: 0\n",
      "Episode 91 finished after 10.000000 time steps\n",
      "Episode 92, t = 13, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992690, Explore rate: 0.434152, Learning rate: 0.434152, Streaks: 0\n",
      "Episode 92 finished after 13.000000 time steps\n",
      "Episode 93, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992753, Explore rate: 0.429457, Learning rate: 0.429457, Streaks: 0\n",
      "Episode 93 finished after 20.000000 time steps\n",
      "Episode 94, t = 10, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992784, Explore rate: 0.424812, Learning rate: 0.424812, Streaks: 0\n",
      "Episode 94 finished after 10.000000 time steps\n",
      "Episode 95, t = 11, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992815, Explore rate: 0.420216, Learning rate: 0.420216, Streaks: 0\n",
      "Episode 95 finished after 11.000000 time steps\n",
      "Episode 96, t = 23, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992845, Explore rate: 0.415669, Learning rate: 0.415669, Streaks: 0\n",
      "Episode 96 finished after 23.000000 time steps\n",
      "Episode 97, t = 61, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992875, Explore rate: 0.411168, Learning rate: 0.411168, Streaks: 0\n",
      "Episode 97 finished after 61.000000 time steps\n",
      "Episode 98, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992933, Explore rate: 0.406714, Learning rate: 0.406714, Streaks: 0\n",
      "Episode 98 finished after 18.000000 time steps\n",
      "Episode 99, t = 13, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992961, Explore rate: 0.402305, Learning rate: 0.402305, Streaks: 0\n",
      "Episode 99 finished after 13.000000 time steps\n",
      "Episode 100, t = 9, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.992990, Explore rate: 0.397940, Learning rate: 0.397940, Streaks: 0\n",
      "Episode 100 finished after 9.000000 time steps\n",
      "Episode 101, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993018, Explore rate: 0.393619, Learning rate: 0.393619, Streaks: 0\n",
      "Episode 101 finished after 17.000000 time steps\n",
      "Episode 102, t = 9, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993045, Explore rate: 0.389340, Learning rate: 0.389340, Streaks: 0\n",
      "Episode 102 finished after 9.000000 time steps\n",
      "Episode 103, t = 10, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993072, Explore rate: 0.385103, Learning rate: 0.385103, Streaks: 0\n",
      "Episode 103 finished after 10.000000 time steps\n",
      "Episode 104, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993099, Explore rate: 0.380907, Learning rate: 0.380907, Streaks: 0\n",
      "Episode 104 finished after 19.000000 time steps\n",
      "Episode 105, t = 11, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993125, Explore rate: 0.376751, Learning rate: 0.376751, Streaks: 0\n",
      "Episode 105 finished after 11.000000 time steps\n",
      "Episode 106, t = 155, action = 1, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 99.143171, Explore rate: 0.372634, Learning rate: 0.372634, Streaks: 0\n",
      "Episode 106 finished after 155.000000 time steps\n",
      "Episode 107, t = 18, action = 1, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 99.149510, Explore rate: 0.368556, Learning rate: 0.368556, Streaks: 0\n",
      "Episode 107 finished after 18.000000 time steps\n",
      "Episode 108, t = 8, action = 1, state = (0, 0, 1, 0), reward = 1.000000\n",
      "\t BestQ: 99.152644, Explore rate: 0.364516, Learning rate: 0.364516, Streaks: 0\n",
      "Episode 108 finished after 8.000000 time steps\n",
      "Episode 109, t = 36, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993176, Explore rate: 0.360514, Learning rate: 0.360514, Streaks: 0\n",
      "Episode 109 finished after 36.000000 time steps\n",
      "Episode 110, t = 11, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993200, Explore rate: 0.356547, Learning rate: 0.356547, Streaks: 0\n",
      "Episode 110 finished after 11.000000 time steps\n",
      "Episode 111, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993248, Explore rate: 0.352617, Learning rate: 0.352617, Streaks: 0\n",
      "Episode 111 finished after 17.000000 time steps\n",
      "Episode 112, t = 9, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993272, Explore rate: 0.348722, Learning rate: 0.348722, Streaks: 0\n",
      "Episode 112 finished after 9.000000 time steps\n",
      "Episode 113, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993319, Explore rate: 0.344862, Learning rate: 0.344862, Streaks: 0\n",
      "Episode 113 finished after 21.000000 time steps\n",
      "Episode 114, t = 12, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993342, Explore rate: 0.341035, Learning rate: 0.341035, Streaks: 0\n",
      "Episode 114 finished after 12.000000 time steps\n",
      "Episode 115, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993387, Explore rate: 0.337242, Learning rate: 0.337242, Streaks: 0\n",
      "Episode 115 finished after 19.000000 time steps\n",
      "Episode 116, t = 9, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993409, Explore rate: 0.333482, Learning rate: 0.333482, Streaks: 0\n",
      "Episode 116 finished after 9.000000 time steps\n",
      "Episode 117, t = 12, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993453, Explore rate: 0.329754, Learning rate: 0.329754, Streaks: 0\n",
      "Episode 117 finished after 12.000000 time steps\n",
      "Episode 118, t = 13, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993474, Explore rate: 0.326058, Learning rate: 0.326058, Streaks: 0\n",
      "Episode 118 finished after 13.000000 time steps\n",
      "Episode 119, t = 9, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993496, Explore rate: 0.322393, Learning rate: 0.322393, Streaks: 0\n",
      "Episode 119 finished after 9.000000 time steps\n",
      "Episode 120, t = 8, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993496, Explore rate: 0.318759, Learning rate: 0.318759, Streaks: 0\n",
      "Episode 120 finished after 8.000000 time steps\n",
      "Episode 121, t = 22, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993537, Explore rate: 0.315155, Learning rate: 0.315155, Streaks: 0\n",
      "Episode 121 finished after 22.000000 time steps\n",
      "Episode 122, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993577, Explore rate: 0.311580, Learning rate: 0.311580, Streaks: 0\n",
      "Episode 122 finished after 21.000000 time steps\n",
      "Episode 123, t = 11, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993597, Explore rate: 0.308035, Learning rate: 0.308035, Streaks: 0\n",
      "Episode 123 finished after 11.000000 time steps\n",
      "Episode 124, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993636, Explore rate: 0.304518, Learning rate: 0.304518, Streaks: 0\n",
      "Episode 124 finished after 18.000000 time steps\n",
      "Episode 125, t = 9, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993655, Explore rate: 0.301030, Learning rate: 0.301030, Streaks: 0\n",
      "Episode 125 finished after 9.000000 time steps\n",
      "Episode 126, t = 26, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993712, Explore rate: 0.297569, Learning rate: 0.297569, Streaks: 0\n",
      "Episode 126 finished after 26.000000 time steps\n",
      "Episode 127, t = 26, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993749, Explore rate: 0.294136, Learning rate: 0.294136, Streaks: 0\n",
      "Episode 127 finished after 26.000000 time steps\n",
      "Episode 128, t = 11, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993768, Explore rate: 0.290730, Learning rate: 0.290730, Streaks: 0\n",
      "Episode 128 finished after 11.000000 time steps\n",
      "Episode 129, t = 14, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993786, Explore rate: 0.287350, Learning rate: 0.287350, Streaks: 0\n",
      "Episode 129 finished after 14.000000 time steps\n",
      "Episode 130, t = 10, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993803, Explore rate: 0.283997, Learning rate: 0.283997, Streaks: 0\n",
      "Episode 130 finished after 10.000000 time steps\n",
      "Episode 131, t = 10, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993821, Explore rate: 0.280669, Learning rate: 0.280669, Streaks: 0\n",
      "Episode 131 finished after 10.000000 time steps\n",
      "Episode 132, t = 10, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993838, Explore rate: 0.277366, Learning rate: 0.277366, Streaks: 0\n",
      "Episode 132 finished after 10.000000 time steps\n",
      "Episode 133, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993889, Explore rate: 0.274088, Learning rate: 0.274088, Streaks: 0\n",
      "Episode 133 finished after 21.000000 time steps\n",
      "Episode 134, t = 9, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993906, Explore rate: 0.270835, Learning rate: 0.270835, Streaks: 0\n",
      "Episode 134 finished after 9.000000 time steps\n",
      "Episode 135, t = 8, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993906, Explore rate: 0.267606, Learning rate: 0.267606, Streaks: 0\n",
      "Episode 135 finished after 8.000000 time steps\n",
      "Episode 136, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993938, Explore rate: 0.264401, Learning rate: 0.264401, Streaks: 0\n",
      "Episode 136 finished after 20.000000 time steps\n",
      "Episode 137, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993970, Explore rate: 0.261219, Learning rate: 0.261219, Streaks: 0\n",
      "Episode 137 finished after 18.000000 time steps\n",
      "Episode 138, t = 7, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.993986, Explore rate: 0.258061, Learning rate: 0.258061, Streaks: 0\n",
      "Episode 138 finished after 7.000000 time steps\n",
      "Episode 139, t = 24, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994032, Explore rate: 0.254925, Learning rate: 0.254925, Streaks: 0\n",
      "Episode 139 finished after 24.000000 time steps\n",
      "Episode 140, t = 25, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994062, Explore rate: 0.251812, Learning rate: 0.251812, Streaks: 0\n",
      "Episode 140 finished after 25.000000 time steps\n",
      "Episode 141, t = 26, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994107, Explore rate: 0.248721, Learning rate: 0.248721, Streaks: 0\n",
      "Episode 141 finished after 26.000000 time steps\n",
      "Episode 142, t = 23, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994150, Explore rate: 0.245652, Learning rate: 0.245652, Streaks: 0\n",
      "Episode 142 finished after 23.000000 time steps\n",
      "Episode 143, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994179, Explore rate: 0.242604, Learning rate: 0.242604, Streaks: 0\n",
      "Episode 143 finished after 21.000000 time steps\n",
      "Episode 144, t = 24, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994193, Explore rate: 0.239578, Learning rate: 0.239578, Streaks: 0\n",
      "Episode 144 finished after 24.000000 time steps\n",
      "Episode 145, t = 9, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994193, Explore rate: 0.236572, Learning rate: 0.236572, Streaks: 0\n",
      "Episode 145 finished after 9.000000 time steps\n",
      "Episode 146, t = 9, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994206, Explore rate: 0.233587, Learning rate: 0.233587, Streaks: 0\n",
      "Episode 146 finished after 9.000000 time steps\n",
      "Episode 147, t = 26, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994233, Explore rate: 0.230623, Learning rate: 0.230623, Streaks: 0\n",
      "Episode 147 finished after 26.000000 time steps\n",
      "Episode 148, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994273, Explore rate: 0.227678, Learning rate: 0.227678, Streaks: 0\n",
      "Episode 148 finished after 22.000000 time steps\n",
      "Episode 149, t = 15, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994311, Explore rate: 0.224754, Learning rate: 0.224754, Streaks: 0\n",
      "Episode 149 finished after 15.000000 time steps\n",
      "Episode 150, t = 24, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994349, Explore rate: 0.221849, Learning rate: 0.221849, Streaks: 0\n",
      "Episode 150 finished after 24.000000 time steps\n",
      "Episode 151, t = 24, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994374, Explore rate: 0.218963, Learning rate: 0.218963, Streaks: 0\n",
      "Episode 151 finished after 24.000000 time steps\n",
      "Episode 152, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994411, Explore rate: 0.216096, Learning rate: 0.216096, Streaks: 0\n",
      "Episode 152 finished after 19.000000 time steps\n",
      "Episode 153, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994446, Explore rate: 0.213249, Learning rate: 0.213249, Streaks: 0\n",
      "Episode 153 finished after 20.000000 time steps\n",
      "Episode 154, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994470, Explore rate: 0.210419, Learning rate: 0.210419, Streaks: 0\n",
      "Episode 154 finished after 18.000000 time steps\n",
      "Episode 155, t = 12, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994493, Explore rate: 0.207608, Learning rate: 0.207608, Streaks: 0\n",
      "Episode 155 finished after 12.000000 time steps\n",
      "Episode 156, t = 8, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994516, Explore rate: 0.204815, Learning rate: 0.204815, Streaks: 0\n",
      "Episode 156 finished after 8.000000 time steps\n",
      "Episode 157, t = 10, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994527, Explore rate: 0.202040, Learning rate: 0.202040, Streaks: 0\n",
      "Episode 157 finished after 10.000000 time steps\n",
      "Episode 158, t = 11, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994527, Explore rate: 0.199283, Learning rate: 0.199283, Streaks: 0\n",
      "Episode 158 finished after 11.000000 time steps\n",
      "Episode 159, t = 12, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994527, Explore rate: 0.196543, Learning rate: 0.196543, Streaks: 0\n",
      "Episode 159 finished after 12.000000 time steps\n",
      "Episode 160, t = 24, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994559, Explore rate: 0.193820, Learning rate: 0.193820, Streaks: 0\n",
      "Episode 160 finished after 24.000000 time steps\n",
      "Episode 161, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994590, Explore rate: 0.191114, Learning rate: 0.191114, Streaks: 0\n",
      "Episode 161 finished after 19.000000 time steps\n",
      "Episode 162, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994621, Explore rate: 0.188425, Learning rate: 0.188425, Streaks: 0\n",
      "Episode 162 finished after 18.000000 time steps\n",
      "Episode 163, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994651, Explore rate: 0.185752, Learning rate: 0.185752, Streaks: 0\n",
      "Episode 163 finished after 22.000000 time steps\n",
      "Episode 164, t = 25, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994671, Explore rate: 0.183096, Learning rate: 0.183096, Streaks: 0\n",
      "Episode 164 finished after 25.000000 time steps\n",
      "Episode 165, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994700, Explore rate: 0.180456, Learning rate: 0.180456, Streaks: 0\n",
      "Episode 165 finished after 18.000000 time steps\n",
      "Episode 166, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994719, Explore rate: 0.177832, Learning rate: 0.177832, Streaks: 0\n",
      "Episode 166 finished after 21.000000 time steps\n",
      "Episode 167, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994737, Explore rate: 0.175224, Learning rate: 0.175224, Streaks: 0\n",
      "Episode 167 finished after 20.000000 time steps\n",
      "Episode 168, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994765, Explore rate: 0.172631, Learning rate: 0.172631, Streaks: 0\n",
      "Episode 168 finished after 22.000000 time steps\n",
      "Episode 169, t = 14, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994782, Explore rate: 0.170053, Learning rate: 0.170053, Streaks: 0\n",
      "Episode 169 finished after 14.000000 time steps\n",
      "Episode 170, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994800, Explore rate: 0.167491, Learning rate: 0.167491, Streaks: 0\n",
      "Episode 170 finished after 21.000000 time steps\n",
      "Episode 171, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994817, Explore rate: 0.164944, Learning rate: 0.164944, Streaks: 0\n",
      "Episode 171 finished after 17.000000 time steps\n",
      "Episode 172, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994834, Explore rate: 0.162412, Learning rate: 0.162412, Streaks: 0\n",
      "Episode 172 finished after 22.000000 time steps\n",
      "Episode 173, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994851, Explore rate: 0.159894, Learning rate: 0.159894, Streaks: 0\n",
      "Episode 173 finished after 16.000000 time steps\n",
      "Episode 174, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994875, Explore rate: 0.157391, Learning rate: 0.157391, Streaks: 0\n",
      "Episode 174 finished after 22.000000 time steps\n",
      "Episode 175, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994899, Explore rate: 0.154902, Learning rate: 0.154902, Streaks: 0\n",
      "Episode 175 finished after 18.000000 time steps\n",
      "Episode 176, t = 19, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994915, Explore rate: 0.152427, Learning rate: 0.152427, Streaks: 0\n",
      "Episode 176 finished after 19.000000 time steps\n",
      "Episode 177, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994930, Explore rate: 0.149967, Learning rate: 0.149967, Streaks: 0\n",
      "Episode 177 finished after 18.000000 time steps\n",
      "Episode 178, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994945, Explore rate: 0.147520, Learning rate: 0.147520, Streaks: 0\n",
      "Episode 178 finished after 18.000000 time steps\n",
      "Episode 179, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994967, Explore rate: 0.145087, Learning rate: 0.145087, Streaks: 0\n",
      "Episode 179 finished after 22.000000 time steps\n",
      "Episode 180, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.994982, Explore rate: 0.142668, Learning rate: 0.142668, Streaks: 0\n",
      "Episode 180 finished after 22.000000 time steps\n",
      "Episode 181, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995003, Explore rate: 0.140261, Learning rate: 0.140261, Streaks: 0\n",
      "Episode 181 finished after 22.000000 time steps\n",
      "Episode 182, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995017, Explore rate: 0.137869, Learning rate: 0.137869, Streaks: 0\n",
      "Episode 182 finished after 20.000000 time steps\n",
      "Episode 183, t = 20, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995037, Explore rate: 0.135489, Learning rate: 0.135489, Streaks: 0\n",
      "Episode 183 finished after 20.000000 time steps\n",
      "Episode 184, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995050, Explore rate: 0.133122, Learning rate: 0.133122, Streaks: 0\n",
      "Episode 184 finished after 16.000000 time steps\n",
      "Episode 185, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995070, Explore rate: 0.130768, Learning rate: 0.130768, Streaks: 0\n",
      "Episode 185 finished after 18.000000 time steps\n",
      "Episode 186, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995083, Explore rate: 0.128427, Learning rate: 0.128427, Streaks: 0\n",
      "Episode 186 finished after 21.000000 time steps\n",
      "Episode 187, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995095, Explore rate: 0.126098, Learning rate: 0.126098, Streaks: 0\n",
      "Episode 187 finished after 18.000000 time steps\n",
      "Episode 188, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995113, Explore rate: 0.123782, Learning rate: 0.123782, Streaks: 0\n",
      "Episode 188 finished after 22.000000 time steps\n",
      "Episode 189, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995125, Explore rate: 0.121478, Learning rate: 0.121478, Streaks: 0\n",
      "Episode 189 finished after 20.000000 time steps\n",
      "Episode 190, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995143, Explore rate: 0.119186, Learning rate: 0.119186, Streaks: 0\n",
      "Episode 190 finished after 20.000000 time steps\n",
      "Episode 191, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995154, Explore rate: 0.116907, Learning rate: 0.116907, Streaks: 0\n",
      "Episode 191 finished after 16.000000 time steps\n",
      "Episode 192, t = 24, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995171, Explore rate: 0.114639, Learning rate: 0.114639, Streaks: 0\n",
      "Episode 192 finished after 24.000000 time steps\n",
      "Episode 193, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995182, Explore rate: 0.112383, Learning rate: 0.112383, Streaks: 0\n",
      "Episode 193 finished after 20.000000 time steps\n",
      "Episode 194, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995193, Explore rate: 0.110138, Learning rate: 0.110138, Streaks: 0\n",
      "Episode 194 finished after 22.000000 time steps\n",
      "Episode 195, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995203, Explore rate: 0.107905, Learning rate: 0.107905, Streaks: 0\n",
      "Episode 195 finished after 22.000000 time steps\n",
      "Episode 196, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995214, Explore rate: 0.105684, Learning rate: 0.105684, Streaks: 0\n",
      "Episode 196 finished after 16.000000 time steps\n",
      "Episode 197, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995229, Explore rate: 0.103474, Learning rate: 0.103474, Streaks: 0\n",
      "Episode 197 finished after 19.000000 time steps\n",
      "Episode 198, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995243, Explore rate: 0.101275, Learning rate: 0.101275, Streaks: 0\n",
      "Episode 198 finished after 22.000000 time steps\n",
      "Episode 199, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995253, Explore rate: 0.099087, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 199 finished after 20.000000 time steps\n",
      "Episode 200, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995267, Explore rate: 0.096910, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 200 finished after 20.000000 time steps\n",
      "Episode 201, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995281, Explore rate: 0.094744, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 201 finished after 20.000000 time steps\n",
      "Episode 202, t = 24, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995291, Explore rate: 0.092589, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 202 finished after 24.000000 time steps\n",
      "Episode 203, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995305, Explore rate: 0.090444, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 203 finished after 16.000000 time steps\n",
      "Episode 204, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995319, Explore rate: 0.088310, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 204 finished after 22.000000 time steps\n",
      "Episode 205, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995328, Explore rate: 0.086186, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 205 finished after 16.000000 time steps\n",
      "Episode 206, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995337, Explore rate: 0.084073, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 206 finished after 18.000000 time steps\n",
      "Episode 207, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995351, Explore rate: 0.081970, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 207 finished after 18.000000 time steps\n",
      "Episode 208, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995365, Explore rate: 0.079877, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 208 finished after 17.000000 time steps\n",
      "Episode 209, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995375, Explore rate: 0.077794, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 209 finished after 18.000000 time steps\n",
      "Episode 210, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995388, Explore rate: 0.075721, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 210 finished after 20.000000 time steps\n",
      "Episode 211, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995402, Explore rate: 0.073658, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 211 finished after 22.000000 time steps\n",
      "Episode 212, t = 15, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995416, Explore rate: 0.071604, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 212 finished after 15.000000 time steps\n",
      "Episode 213, t = 14, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995425, Explore rate: 0.069560, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 213 finished after 14.000000 time steps\n",
      "Episode 214, t = 24, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995439, Explore rate: 0.067526, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 214 finished after 24.000000 time steps\n",
      "Episode 215, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995453, Explore rate: 0.065502, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 215 finished after 16.000000 time steps\n",
      "Episode 216, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995466, Explore rate: 0.063486, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 216 finished after 19.000000 time steps\n",
      "Episode 217, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995475, Explore rate: 0.061480, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 217 finished after 20.000000 time steps\n",
      "Episode 218, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995489, Explore rate: 0.059484, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 218 finished after 18.000000 time steps\n",
      "Episode 219, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995502, Explore rate: 0.057496, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 219 finished after 22.000000 time steps\n",
      "Episode 220, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995516, Explore rate: 0.055517, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 220 finished after 18.000000 time steps\n",
      "Episode 221, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995529, Explore rate: 0.053548, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 221 finished after 18.000000 time steps\n",
      "Episode 222, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995543, Explore rate: 0.051587, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 222 finished after 19.000000 time steps\n",
      "Episode 223, t = 23, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995556, Explore rate: 0.049635, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 223 finished after 23.000000 time steps\n",
      "Episode 224, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995565, Explore rate: 0.047692, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 224 finished after 18.000000 time steps\n",
      "Episode 225, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995574, Explore rate: 0.045757, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 225 finished after 20.000000 time steps\n",
      "Episode 226, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995583, Explore rate: 0.043832, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 226 finished after 20.000000 time steps\n",
      "Episode 227, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995596, Explore rate: 0.041914, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 227 finished after 21.000000 time steps\n",
      "Episode 228, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995609, Explore rate: 0.040005, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 228 finished after 21.000000 time steps\n",
      "Episode 229, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995622, Explore rate: 0.038105, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 229 finished after 19.000000 time steps\n",
      "Episode 230, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995635, Explore rate: 0.036212, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 230 finished after 21.000000 time steps\n",
      "Episode 231, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995648, Explore rate: 0.034328, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 231 finished after 20.000000 time steps\n",
      "Episode 232, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995657, Explore rate: 0.032452, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 232 finished after 18.000000 time steps\n",
      "Episode 233, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995670, Explore rate: 0.030584, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 233 finished after 18.000000 time steps\n",
      "Episode 234, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995679, Explore rate: 0.028724, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 234 finished after 20.000000 time steps\n",
      "Episode 235, t = 24, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995692, Explore rate: 0.026872, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 235 finished after 24.000000 time steps\n",
      "Episode 236, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995700, Explore rate: 0.025028, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 236 finished after 16.000000 time steps\n",
      "Episode 237, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995709, Explore rate: 0.023192, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 237 finished after 18.000000 time steps\n",
      "Episode 238, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995722, Explore rate: 0.021363, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 238 finished after 16.000000 time steps\n",
      "Episode 239, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995735, Explore rate: 0.019542, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 239 finished after 22.000000 time steps\n",
      "Episode 240, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995743, Explore rate: 0.017729, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 240 finished after 20.000000 time steps\n",
      "Episode 241, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995756, Explore rate: 0.015923, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 241 finished after 20.000000 time steps\n",
      "Episode 242, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995769, Explore rate: 0.014125, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 242 finished after 16.000000 time steps\n",
      "Episode 243, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995781, Explore rate: 0.012334, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 243 finished after 22.000000 time steps\n",
      "Episode 244, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995790, Explore rate: 0.010550, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 244 finished after 22.000000 time steps\n",
      "Episode 245, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995802, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 245 finished after 19.000000 time steps\n",
      "Episode 246, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995815, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 246 finished after 17.000000 time steps\n",
      "Episode 247, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995823, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 247 finished after 19.000000 time steps\n",
      "Episode 248, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995832, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 248 finished after 22.000000 time steps\n",
      "Episode 249, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995844, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 249 finished after 18.000000 time steps\n",
      "Episode 250, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995857, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 250 finished after 20.000000 time steps\n",
      "Episode 251, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995869, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 251 finished after 17.000000 time steps\n",
      "Episode 252, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995877, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 252 finished after 21.000000 time steps\n",
      "Episode 253, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995890, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 253 finished after 18.000000 time steps\n",
      "Episode 254, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995898, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 254 finished after 18.000000 time steps\n",
      "Episode 255, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995906, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 255 finished after 22.000000 time steps\n",
      "Episode 256, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995914, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 256 finished after 17.000000 time steps\n",
      "Episode 257, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995922, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 257 finished after 22.000000 time steps\n",
      "Episode 258, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995931, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 258 finished after 16.000000 time steps\n",
      "Episode 259, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995943, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 259 finished after 20.000000 time steps\n",
      "Episode 260, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995951, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 260 finished after 16.000000 time steps\n",
      "Episode 261, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995963, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 261 finished after 22.000000 time steps\n",
      "Episode 262, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995975, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 262 finished after 21.000000 time steps\n",
      "Episode 263, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995987, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 263 finished after 20.000000 time steps\n",
      "Episode 264, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.995995, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 264 finished after 20.000000 time steps\n",
      "Episode 265, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996003, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 265 finished after 20.000000 time steps\n",
      "Episode 266, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996015, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 266 finished after 20.000000 time steps\n",
      "Episode 267, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996023, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 267 finished after 20.000000 time steps\n",
      "Episode 268, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996035, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 268 finished after 18.000000 time steps\n",
      "Episode 269, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996047, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 269 finished after 18.000000 time steps\n",
      "Episode 270, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996059, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 270 finished after 21.000000 time steps\n",
      "Episode 271, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996071, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 271 finished after 18.000000 time steps\n",
      "Episode 272, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996082, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 272 finished after 18.000000 time steps\n",
      "Episode 273, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996094, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 273 finished after 22.000000 time steps\n",
      "Episode 274, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996106, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 274 finished after 18.000000 time steps\n",
      "Episode 275, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996114, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 275 finished after 20.000000 time steps\n",
      "Episode 276, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996121, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 276 finished after 20.000000 time steps\n",
      "Episode 277, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996133, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 277 finished after 21.000000 time steps\n",
      "Episode 278, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996141, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 278 finished after 20.000000 time steps\n",
      "Episode 279, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996152, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 279 finished after 18.000000 time steps\n",
      "Episode 280, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996164, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 280 finished after 22.000000 time steps\n",
      "Episode 281, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996175, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 281 finished after 16.000000 time steps\n",
      "Episode 282, t = 24, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996187, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 282 finished after 24.000000 time steps\n",
      "Episode 283, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996198, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 283 finished after 22.000000 time steps\n",
      "Episode 284, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996206, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 284 finished after 16.000000 time steps\n",
      "Episode 285, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996217, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 285 finished after 22.000000 time steps\n",
      "Episode 286, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996229, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 286 finished after 20.000000 time steps\n",
      "Episode 287, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996240, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 287 finished after 22.000000 time steps\n",
      "Episode 288, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996251, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 288 finished after 18.000000 time steps\n",
      "Episode 289, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996262, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 289 finished after 21.000000 time steps\n",
      "Episode 290, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996270, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 290 finished after 20.000000 time steps\n",
      "Episode 291, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996277, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 291 finished after 20.000000 time steps\n",
      "Episode 292, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996288, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 292 finished after 22.000000 time steps\n",
      "Episode 293, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996300, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 293 finished after 20.000000 time steps\n",
      "Episode 294, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996311, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 294 finished after 21.000000 time steps\n",
      "Episode 295, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996318, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 295 finished after 20.000000 time steps\n",
      "Episode 296, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996329, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 296 finished after 17.000000 time steps\n",
      "Episode 297, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996336, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 297 finished after 20.000000 time steps\n",
      "Episode 298, t = 23, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996347, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 298 finished after 23.000000 time steps\n",
      "Episode 299, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996355, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 299 finished after 22.000000 time steps\n",
      "Episode 300, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996366, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 300 finished after 19.000000 time steps\n",
      "Episode 301, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996376, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 301 finished after 21.000000 time steps\n",
      "Episode 302, t = 23, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996387, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 302 finished after 23.000000 time steps\n",
      "Episode 303, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996395, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 303 finished after 20.000000 time steps\n",
      "Episode 304, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996402, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 304 finished after 18.000000 time steps\n",
      "Episode 305, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996409, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 305 finished after 16.000000 time steps\n",
      "Episode 306, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996420, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 306 finished after 21.000000 time steps\n",
      "Episode 307, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996427, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 307 finished after 22.000000 time steps\n",
      "Episode 308, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996434, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 308 finished after 20.000000 time steps\n",
      "Episode 309, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996441, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 309 finished after 22.000000 time steps\n",
      "Episode 310, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996452, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 310 finished after 16.000000 time steps\n",
      "Episode 311, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996462, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 311 finished after 19.000000 time steps\n",
      "Episode 312, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996470, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 312 finished after 17.000000 time steps\n",
      "Episode 313, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996477, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 313 finished after 21.000000 time steps\n",
      "Episode 314, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996487, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 314 finished after 21.000000 time steps\n",
      "Episode 315, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996494, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 315 finished after 16.000000 time steps\n",
      "Episode 316, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996505, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 316 finished after 19.000000 time steps\n",
      "Episode 317, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996515, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 317 finished after 19.000000 time steps\n",
      "Episode 318, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996526, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 318 finished after 18.000000 time steps\n",
      "Episode 319, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996533, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 319 finished after 22.000000 time steps\n",
      "Episode 320, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996543, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 320 finished after 19.000000 time steps\n",
      "Episode 321, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996550, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 321 finished after 17.000000 time steps\n",
      "Episode 322, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996560, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 322 finished after 22.000000 time steps\n",
      "Episode 323, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996570, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 323 finished after 21.000000 time steps\n",
      "Episode 324, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996581, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 324 finished after 20.000000 time steps\n",
      "Episode 325, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996591, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 325 finished after 19.000000 time steps\n",
      "Episode 326, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996601, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 326 finished after 22.000000 time steps\n",
      "Episode 327, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996611, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 327 finished after 21.000000 time steps\n",
      "Episode 328, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996622, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 328 finished after 20.000000 time steps\n",
      "Episode 329, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996632, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 329 finished after 17.000000 time steps\n",
      "Episode 330, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996642, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 330 finished after 22.000000 time steps\n",
      "Episode 331, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996652, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 331 finished after 22.000000 time steps\n",
      "Episode 332, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996662, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 332 finished after 18.000000 time steps\n",
      "Episode 333, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996669, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 333 finished after 18.000000 time steps\n",
      "Episode 334, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996679, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 334 finished after 18.000000 time steps\n",
      "Episode 335, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996685, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 335 finished after 20.000000 time steps\n",
      "Episode 336, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996695, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 336 finished after 18.000000 time steps\n",
      "Episode 337, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996702, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 337 finished after 18.000000 time steps\n",
      "Episode 338, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996712, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 338 finished after 19.000000 time steps\n",
      "Episode 339, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996721, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 339 finished after 18.000000 time steps\n",
      "Episode 340, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996728, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 340 finished after 20.000000 time steps\n",
      "Episode 341, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996738, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 341 finished after 20.000000 time steps\n",
      "Episode 342, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996744, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 342 finished after 20.000000 time steps\n",
      "Episode 343, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996754, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 343 finished after 19.000000 time steps\n",
      "Episode 344, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996761, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 344 finished after 20.000000 time steps\n",
      "Episode 345, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996767, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 345 finished after 20.000000 time steps\n",
      "Episode 346, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996774, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 346 finished after 20.000000 time steps\n",
      "Episode 347, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996783, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 347 finished after 20.000000 time steps\n",
      "Episode 348, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996793, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 348 finished after 19.000000 time steps\n",
      "Episode 349, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996802, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 349 finished after 21.000000 time steps\n",
      "Episode 350, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996812, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 350 finished after 19.000000 time steps\n",
      "Episode 351, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996822, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 351 finished after 17.000000 time steps\n",
      "Episode 352, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996831, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 352 finished after 21.000000 time steps\n",
      "Episode 353, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996841, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 353 finished after 20.000000 time steps\n",
      "Episode 354, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996850, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 354 finished after 21.000000 time steps\n",
      "Episode 355, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996860, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 355 finished after 21.000000 time steps\n",
      "Episode 356, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996869, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 356 finished after 20.000000 time steps\n",
      "Episode 357, t = 24, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996878, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 357 finished after 24.000000 time steps\n",
      "Episode 358, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996888, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 358 finished after 18.000000 time steps\n",
      "Episode 359, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996897, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 359 finished after 21.000000 time steps\n",
      "Episode 360, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996906, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 360 finished after 21.000000 time steps\n",
      "Episode 361, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996916, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 361 finished after 22.000000 time steps\n",
      "Episode 362, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996922, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 362 finished after 20.000000 time steps\n",
      "Episode 363, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996931, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 363 finished after 21.000000 time steps\n",
      "Episode 364, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996937, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 364 finished after 18.000000 time steps\n",
      "Episode 365, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996946, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 365 finished after 21.000000 time steps\n",
      "Episode 366, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996955, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 366 finished after 18.000000 time steps\n",
      "Episode 367, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996962, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 367 finished after 16.000000 time steps\n",
      "Episode 368, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996968, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 368 finished after 18.000000 time steps\n",
      "Episode 369, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996977, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 369 finished after 16.000000 time steps\n",
      "Episode 370, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996983, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 370 finished after 22.000000 time steps\n",
      "Episode 371, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996989, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 371 finished after 16.000000 time steps\n",
      "Episode 372, t = 15, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.996998, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 372 finished after 15.000000 time steps\n",
      "Episode 373, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997007, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 373 finished after 19.000000 time steps\n",
      "Episode 374, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997013, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 374 finished after 20.000000 time steps\n",
      "Episode 375, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997022, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 375 finished after 16.000000 time steps\n",
      "Episode 376, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997028, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 376 finished after 22.000000 time steps\n",
      "Episode 377, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997037, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 377 finished after 20.000000 time steps\n",
      "Episode 378, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997043, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 378 finished after 20.000000 time steps\n",
      "Episode 379, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997051, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 379 finished after 21.000000 time steps\n",
      "Episode 380, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997060, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 380 finished after 21.000000 time steps\n",
      "Episode 381, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997066, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 381 finished after 16.000000 time steps\n",
      "Episode 382, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997072, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 382 finished after 20.000000 time steps\n",
      "Episode 383, t = 23, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997078, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 383 finished after 23.000000 time steps\n",
      "Episode 384, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997084, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 384 finished after 20.000000 time steps\n",
      "Episode 385, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997092, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 385 finished after 18.000000 time steps\n",
      "Episode 386, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997101, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 386 finished after 22.000000 time steps\n",
      "Episode 387, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997107, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 387 finished after 22.000000 time steps\n",
      "Episode 388, t = 23, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997116, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 388 finished after 23.000000 time steps\n",
      "Episode 389, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997124, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 389 finished after 20.000000 time steps\n",
      "Episode 390, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997133, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 390 finished after 18.000000 time steps\n",
      "Episode 391, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997139, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 391 finished after 20.000000 time steps\n",
      "Episode 392, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997147, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 392 finished after 22.000000 time steps\n",
      "Episode 393, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997156, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 393 finished after 21.000000 time steps\n",
      "Episode 394, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997161, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 394 finished after 18.000000 time steps\n",
      "Episode 395, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997170, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 395 finished after 21.000000 time steps\n",
      "Episode 396, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997178, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 396 finished after 18.000000 time steps\n",
      "Episode 397, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997187, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 397 finished after 18.000000 time steps\n",
      "Episode 398, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997195, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 398 finished after 18.000000 time steps\n",
      "Episode 399, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997204, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 399 finished after 20.000000 time steps\n",
      "Episode 400, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997212, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 400 finished after 20.000000 time steps\n",
      "Episode 401, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997218, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 401 finished after 20.000000 time steps\n",
      "Episode 402, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997226, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 402 finished after 19.000000 time steps\n",
      "Episode 403, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997234, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 403 finished after 21.000000 time steps\n",
      "Episode 404, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997243, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 404 finished after 20.000000 time steps\n",
      "Episode 405, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997251, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 405 finished after 16.000000 time steps\n",
      "Episode 406, t = 23, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997259, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 406 finished after 23.000000 time steps\n",
      "Episode 407, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997267, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 407 finished after 20.000000 time steps\n",
      "Episode 408, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997275, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 408 finished after 22.000000 time steps\n",
      "Episode 409, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997281, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 409 finished after 16.000000 time steps\n",
      "Episode 410, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997289, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 410 finished after 22.000000 time steps\n",
      "Episode 411, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997297, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 411 finished after 20.000000 time steps\n",
      "Episode 412, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997305, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 412 finished after 22.000000 time steps\n",
      "Episode 413, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997313, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 413 finished after 22.000000 time steps\n",
      "Episode 414, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997321, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 414 finished after 20.000000 time steps\n",
      "Episode 415, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997329, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 415 finished after 21.000000 time steps\n",
      "Episode 416, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997337, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 416 finished after 21.000000 time steps\n",
      "Episode 417, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997343, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 417 finished after 20.000000 time steps\n",
      "Episode 418, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997351, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 418 finished after 19.000000 time steps\n",
      "Episode 419, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997359, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 419 finished after 19.000000 time steps\n",
      "Episode 420, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997367, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 420 finished after 22.000000 time steps\n",
      "Episode 421, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997374, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 421 finished after 22.000000 time steps\n",
      "Episode 422, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997382, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 422 finished after 20.000000 time steps\n",
      "Episode 423, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997390, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 423 finished after 22.000000 time steps\n",
      "Episode 424, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997398, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 424 finished after 20.000000 time steps\n",
      "Episode 425, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997406, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 425 finished after 17.000000 time steps\n",
      "Episode 426, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997414, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 426 finished after 21.000000 time steps\n",
      "Episode 427, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997419, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 427 finished after 22.000000 time steps\n",
      "Episode 428, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997426, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 428 finished after 22.000000 time steps\n",
      "Episode 429, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997434, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 429 finished after 18.000000 time steps\n",
      "Episode 430, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997442, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 430 finished after 19.000000 time steps\n",
      "Episode 431, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997450, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 431 finished after 19.000000 time steps\n",
      "Episode 432, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997457, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 432 finished after 22.000000 time steps\n",
      "Episode 433, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997465, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 433 finished after 18.000000 time steps\n",
      "Episode 434, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997470, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 434 finished after 16.000000 time steps\n",
      "Episode 435, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997477, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 435 finished after 19.000000 time steps\n",
      "Episode 436, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997485, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 436 finished after 21.000000 time steps\n",
      "Episode 437, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997493, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 437 finished after 20.000000 time steps\n",
      "Episode 438, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997500, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 438 finished after 21.000000 time steps\n",
      "Episode 439, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997505, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 439 finished after 20.000000 time steps\n",
      "Episode 440, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997513, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 440 finished after 20.000000 time steps\n",
      "Episode 441, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997520, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 441 finished after 22.000000 time steps\n",
      "Episode 442, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997525, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 442 finished after 21.000000 time steps\n",
      "Episode 443, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997532, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 443 finished after 18.000000 time steps\n",
      "Episode 444, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997540, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 444 finished after 22.000000 time steps\n",
      "Episode 445, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997547, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 445 finished after 17.000000 time steps\n",
      "Episode 446, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997555, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 446 finished after 21.000000 time steps\n",
      "Episode 447, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997562, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 447 finished after 21.000000 time steps\n",
      "Episode 448, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997567, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 448 finished after 20.000000 time steps\n",
      "Episode 449, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997574, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 449 finished after 20.000000 time steps\n",
      "Episode 450, t = 20, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997579, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 450 finished after 20.000000 time steps\n",
      "Episode 451, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997584, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 451 finished after 16.000000 time steps\n",
      "Episode 452, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997591, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 452 finished after 20.000000 time steps\n",
      "Episode 453, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997596, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 453 finished after 18.000000 time steps\n",
      "Episode 454, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997601, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 454 finished after 18.000000 time steps\n",
      "Episode 455, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997605, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 455 finished after 20.000000 time steps\n",
      "Episode 456, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997613, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 456 finished after 18.000000 time steps\n",
      "Episode 457, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997617, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 457 finished after 20.000000 time steps\n",
      "Episode 458, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997622, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 458 finished after 20.000000 time steps\n",
      "Episode 459, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997629, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 459 finished after 21.000000 time steps\n",
      "Episode 460, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997636, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 460 finished after 21.000000 time steps\n",
      "Episode 461, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997641, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 461 finished after 18.000000 time steps\n",
      "Episode 462, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997646, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 462 finished after 22.000000 time steps\n",
      "Episode 463, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997650, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 463 finished after 18.000000 time steps\n",
      "Episode 464, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997655, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 464 finished after 20.000000 time steps\n",
      "Episode 465, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997662, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 465 finished after 20.000000 time steps\n",
      "Episode 466, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997669, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 466 finished after 19.000000 time steps\n",
      "Episode 467, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997676, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 467 finished after 17.000000 time steps\n",
      "Episode 468, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997683, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 468 finished after 19.000000 time steps\n",
      "Episode 469, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997690, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 469 finished after 16.000000 time steps\n",
      "Episode 470, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997695, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 470 finished after 18.000000 time steps\n",
      "Episode 471, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997699, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 471 finished after 16.000000 time steps\n",
      "Episode 472, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997704, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 472 finished after 16.000000 time steps\n",
      "Episode 473, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997708, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 473 finished after 16.000000 time steps\n",
      "Episode 474, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997715, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 474 finished after 21.000000 time steps\n",
      "Episode 475, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997722, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 475 finished after 22.000000 time steps\n",
      "Episode 476, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997729, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 476 finished after 21.000000 time steps\n",
      "Episode 477, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997736, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 477 finished after 16.000000 time steps\n",
      "Episode 478, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997743, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 478 finished after 18.000000 time steps\n",
      "Episode 479, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997749, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 479 finished after 18.000000 time steps\n",
      "Episode 480, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997756, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 480 finished after 22.000000 time steps\n",
      "Episode 481, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997763, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 481 finished after 19.000000 time steps\n",
      "Episode 482, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997767, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 482 finished after 22.000000 time steps\n",
      "Episode 483, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997772, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 483 finished after 18.000000 time steps\n",
      "Episode 484, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997776, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 484 finished after 18.000000 time steps\n",
      "Episode 485, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997783, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 485 finished after 22.000000 time steps\n",
      "Episode 486, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997790, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 486 finished after 20.000000 time steps\n",
      "Episode 487, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997796, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 487 finished after 17.000000 time steps\n",
      "Episode 488, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997801, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 488 finished after 18.000000 time steps\n",
      "Episode 489, t = 15, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997805, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 489 finished after 15.000000 time steps\n",
      "Episode 490, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997809, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 490 finished after 22.000000 time steps\n",
      "Episode 491, t = 14, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997814, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 491 finished after 14.000000 time steps\n",
      "Episode 492, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997818, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 492 finished after 20.000000 time steps\n",
      "Episode 493, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997825, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 493 finished after 18.000000 time steps\n",
      "Episode 494, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997829, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 494 finished after 20.000000 time steps\n",
      "Episode 495, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997833, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 495 finished after 22.000000 time steps\n",
      "Episode 496, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997840, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 496 finished after 18.000000 time steps\n",
      "Episode 497, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997844, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 497 finished after 20.000000 time steps\n",
      "Episode 498, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997851, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 498 finished after 19.000000 time steps\n",
      "Episode 499, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997855, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 499 finished after 16.000000 time steps\n",
      "Episode 500, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997859, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 500 finished after 18.000000 time steps\n",
      "Episode 501, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997863, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 501 finished after 22.000000 time steps\n",
      "Episode 502, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997870, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 502 finished after 18.000000 time steps\n",
      "Episode 503, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997876, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 503 finished after 22.000000 time steps\n",
      "Episode 504, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997881, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 504 finished after 20.000000 time steps\n",
      "Episode 505, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997885, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 505 finished after 20.000000 time steps\n",
      "Episode 506, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997891, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 506 finished after 18.000000 time steps\n",
      "Episode 507, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997897, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 507 finished after 16.000000 time steps\n",
      "Episode 508, t = 23, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997902, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 508 finished after 23.000000 time steps\n",
      "Episode 509, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997906, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 509 finished after 16.000000 time steps\n",
      "Episode 510, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997910, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 510 finished after 19.000000 time steps\n",
      "Episode 511, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997914, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 511 finished after 18.000000 time steps\n",
      "Episode 512, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997920, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 512 finished after 20.000000 time steps\n",
      "Episode 513, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997925, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 513 finished after 20.000000 time steps\n",
      "Episode 514, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997931, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 514 finished after 18.000000 time steps\n",
      "Episode 515, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997937, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 515 finished after 18.000000 time steps\n",
      "Episode 516, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997943, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 516 finished after 18.000000 time steps\n",
      "Episode 517, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997947, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 517 finished after 22.000000 time steps\n",
      "Episode 518, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997953, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 518 finished after 19.000000 time steps\n",
      "Episode 519, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997958, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 519 finished after 20.000000 time steps\n",
      "Episode 520, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997964, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 520 finished after 22.000000 time steps\n",
      "Episode 521, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997970, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 521 finished after 17.000000 time steps\n",
      "Episode 522, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997974, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 522 finished after 16.000000 time steps\n",
      "Episode 523, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997980, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 523 finished after 21.000000 time steps\n",
      "Episode 524, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997984, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 524 finished after 20.000000 time steps\n",
      "Episode 525, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997988, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 525 finished after 20.000000 time steps\n",
      "Episode 526, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997992, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 526 finished after 20.000000 time steps\n",
      "Episode 527, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.997996, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 527 finished after 22.000000 time steps\n",
      "Episode 528, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998000, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 528 finished after 22.000000 time steps\n",
      "Episode 529, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998006, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 529 finished after 22.000000 time steps\n",
      "Episode 530, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998012, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 530 finished after 19.000000 time steps\n",
      "Episode 531, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998018, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 531 finished after 22.000000 time steps\n",
      "Episode 532, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998024, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 532 finished after 18.000000 time steps\n",
      "Episode 533, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998030, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 533 finished after 17.000000 time steps\n",
      "Episode 534, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998036, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 534 finished after 20.000000 time steps\n",
      "Episode 535, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998042, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 535 finished after 19.000000 time steps\n",
      "Episode 536, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998047, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 536 finished after 22.000000 time steps\n",
      "Episode 537, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998053, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 537 finished after 19.000000 time steps\n",
      "Episode 538, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998057, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 538 finished after 22.000000 time steps\n",
      "Episode 539, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998061, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 539 finished after 19.000000 time steps\n",
      "Episode 540, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998067, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 540 finished after 21.000000 time steps\n",
      "Episode 541, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998073, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 541 finished after 22.000000 time steps\n",
      "Episode 542, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998078, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 542 finished after 22.000000 time steps\n",
      "Episode 543, t = 23, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998084, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 543 finished after 23.000000 time steps\n",
      "Episode 544, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998088, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 544 finished after 20.000000 time steps\n",
      "Episode 545, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998094, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 545 finished after 20.000000 time steps\n",
      "Episode 546, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998099, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 546 finished after 20.000000 time steps\n",
      "Episode 547, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998105, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 547 finished after 22.000000 time steps\n",
      "Episode 548, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998111, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 548 finished after 20.000000 time steps\n",
      "Episode 549, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998117, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 549 finished after 20.000000 time steps\n",
      "Episode 550, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998122, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 550 finished after 20.000000 time steps\n",
      "Episode 551, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998128, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 551 finished after 22.000000 time steps\n",
      "Episode 552, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998132, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 552 finished after 20.000000 time steps\n",
      "Episode 553, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998137, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 553 finished after 17.000000 time steps\n",
      "Episode 554, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998143, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 554 finished after 21.000000 time steps\n",
      "Episode 555, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998146, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 555 finished after 16.000000 time steps\n",
      "Episode 556, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998150, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 556 finished after 22.000000 time steps\n",
      "Episode 557, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998156, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 557 finished after 16.000000 time steps\n",
      "Episode 558, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998161, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 558 finished after 21.000000 time steps\n",
      "Episode 559, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998165, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 559 finished after 16.000000 time steps\n",
      "Episode 560, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998169, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 560 finished after 18.000000 time steps\n",
      "Episode 561, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998172, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 561 finished after 18.000000 time steps\n",
      "Episode 562, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998178, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 562 finished after 19.000000 time steps\n",
      "Episode 563, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998183, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 563 finished after 21.000000 time steps\n",
      "Episode 564, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998189, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 564 finished after 18.000000 time steps\n",
      "Episode 565, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998194, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 565 finished after 20.000000 time steps\n",
      "Episode 566, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998199, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 566 finished after 21.000000 time steps\n",
      "Episode 567, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998205, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 567 finished after 18.000000 time steps\n",
      "Episode 568, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998210, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 568 finished after 16.000000 time steps\n",
      "Episode 569, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998214, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 569 finished after 20.000000 time steps\n",
      "Episode 570, t = 17, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998219, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 570 finished after 17.000000 time steps\n",
      "Episode 571, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998223, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 571 finished after 20.000000 time steps\n",
      "Episode 572, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998226, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 572 finished after 18.000000 time steps\n",
      "Episode 573, t = 23, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998232, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 573 finished after 23.000000 time steps\n",
      "Episode 574, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998235, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 574 finished after 17.000000 time steps\n",
      "Episode 575, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998240, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 575 finished after 19.000000 time steps\n",
      "Episode 576, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998244, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 576 finished after 18.000000 time steps\n",
      "Episode 577, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998249, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 577 finished after 21.000000 time steps\n",
      "Episode 578, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998254, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 578 finished after 17.000000 time steps\n",
      "Episode 579, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998260, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 579 finished after 21.000000 time steps\n",
      "Episode 580, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998263, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 580 finished after 20.000000 time steps\n",
      "Episode 581, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998267, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 581 finished after 20.000000 time steps\n",
      "Episode 582, t = 24, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998272, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 582 finished after 24.000000 time steps\n",
      "Episode 583, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998275, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 583 finished after 20.000000 time steps\n",
      "Episode 584, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998280, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 584 finished after 17.000000 time steps\n",
      "Episode 585, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998284, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 585 finished after 20.000000 time steps\n",
      "Episode 586, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998287, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 586 finished after 18.000000 time steps\n",
      "Episode 587, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998292, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 587 finished after 16.000000 time steps\n",
      "Episode 588, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998298, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 588 finished after 19.000000 time steps\n",
      "Episode 589, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998301, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 589 finished after 20.000000 time steps\n",
      "Episode 590, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998304, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 590 finished after 18.000000 time steps\n",
      "Episode 591, t = 15, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998309, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 591 finished after 15.000000 time steps\n",
      "Episode 592, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998313, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 592 finished after 22.000000 time steps\n",
      "Episode 593, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998316, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 593 finished after 18.000000 time steps\n",
      "Episode 594, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998320, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 594 finished after 20.000000 time steps\n",
      "Episode 595, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998323, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 595 finished after 22.000000 time steps\n",
      "Episode 596, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998328, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 596 finished after 20.000000 time steps\n",
      "Episode 597, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998333, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 597 finished after 21.000000 time steps\n",
      "Episode 598, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998338, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 598 finished after 22.000000 time steps\n",
      "Episode 599, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998343, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 599 finished after 16.000000 time steps\n",
      "Episode 600, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998348, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 600 finished after 20.000000 time steps\n",
      "Episode 601, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998353, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 601 finished after 22.000000 time steps\n",
      "Episode 602, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998358, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 602 finished after 22.000000 time steps\n",
      "Episode 603, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998363, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 603 finished after 19.000000 time steps\n",
      "Episode 604, t = 23, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998368, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 604 finished after 23.000000 time steps\n",
      "Episode 605, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998371, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 605 finished after 16.000000 time steps\n",
      "Episode 606, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998374, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 606 finished after 20.000000 time steps\n",
      "Episode 607, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998377, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 607 finished after 20.000000 time steps\n",
      "Episode 608, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998382, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 608 finished after 22.000000 time steps\n",
      "Episode 609, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998385, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 609 finished after 19.000000 time steps\n",
      "Episode 610, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998389, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 610 finished after 18.000000 time steps\n",
      "Episode 611, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998394, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 611 finished after 18.000000 time steps\n",
      "Episode 612, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998398, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 612 finished after 18.000000 time steps\n",
      "Episode 613, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998403, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 613 finished after 22.000000 time steps\n",
      "Episode 614, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998408, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 614 finished after 19.000000 time steps\n",
      "Episode 615, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998411, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 615 finished after 20.000000 time steps\n",
      "Episode 616, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998414, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 616 finished after 20.000000 time steps\n",
      "Episode 617, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998419, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 617 finished after 22.000000 time steps\n",
      "Episode 618, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998424, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 618 finished after 21.000000 time steps\n",
      "Episode 619, t = 23, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998429, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 619 finished after 23.000000 time steps\n",
      "Episode 620, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998433, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 620 finished after 20.000000 time steps\n",
      "Episode 621, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998438, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 621 finished after 19.000000 time steps\n",
      "Episode 622, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998441, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 622 finished after 16.000000 time steps\n",
      "Episode 623, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998446, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 623 finished after 20.000000 time steps\n",
      "Episode 624, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998450, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 624 finished after 20.000000 time steps\n",
      "Episode 625, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998455, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 625 finished after 19.000000 time steps\n",
      "Episode 626, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998460, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 626 finished after 21.000000 time steps\n",
      "Episode 627, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998464, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 627 finished after 17.000000 time steps\n",
      "Episode 628, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998467, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 628 finished after 22.000000 time steps\n",
      "Episode 629, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998472, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 629 finished after 16.000000 time steps\n",
      "Episode 630, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998476, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 630 finished after 18.000000 time steps\n",
      "Episode 631, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998480, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 631 finished after 18.000000 time steps\n",
      "Episode 632, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998483, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 632 finished after 18.000000 time steps\n",
      "Episode 633, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998487, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 633 finished after 17.000000 time steps\n",
      "Episode 634, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998492, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 634 finished after 21.000000 time steps\n",
      "Episode 635, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998495, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 635 finished after 16.000000 time steps\n",
      "Episode 636, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998499, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 636 finished after 19.000000 time steps\n",
      "Episode 637, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998504, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 637 finished after 18.000000 time steps\n",
      "Episode 638, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998508, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 638 finished after 22.000000 time steps\n",
      "Episode 639, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998511, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 639 finished after 21.000000 time steps\n",
      "Episode 640, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998514, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 640 finished after 18.000000 time steps\n",
      "Episode 641, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998517, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 641 finished after 20.000000 time steps\n",
      "Episode 642, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998522, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 642 finished after 18.000000 time steps\n",
      "Episode 643, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998525, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 643 finished after 20.000000 time steps\n",
      "Episode 644, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998529, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 644 finished after 21.000000 time steps\n",
      "Episode 645, t = 15, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998532, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 645 finished after 15.000000 time steps\n",
      "Episode 646, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998535, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 646 finished after 18.000000 time steps\n",
      "Episode 647, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998539, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 647 finished after 18.000000 time steps\n",
      "Episode 648, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998544, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 648 finished after 18.000000 time steps\n",
      "Episode 649, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998548, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 649 finished after 17.000000 time steps\n",
      "Episode 650, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998552, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 650 finished after 21.000000 time steps\n",
      "Episode 651, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998557, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 651 finished after 19.000000 time steps\n",
      "Episode 652, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998560, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 652 finished after 20.000000 time steps\n",
      "Episode 653, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998564, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 653 finished after 21.000000 time steps\n",
      "Episode 654, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998567, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 654 finished after 22.000000 time steps\n",
      "Episode 655, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998570, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 655 finished after 16.000000 time steps\n",
      "Episode 656, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998574, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 656 finished after 18.000000 time steps\n",
      "Episode 657, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998577, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 657 finished after 22.000000 time steps\n",
      "Episode 658, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998581, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 658 finished after 17.000000 time steps\n",
      "Episode 659, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998584, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 659 finished after 22.000000 time steps\n",
      "Episode 660, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998588, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 660 finished after 18.000000 time steps\n",
      "Episode 661, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998591, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 661 finished after 22.000000 time steps\n",
      "Episode 662, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998595, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 662 finished after 22.000000 time steps\n",
      "Episode 663, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998598, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 663 finished after 20.000000 time steps\n",
      "Episode 664, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998601, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 664 finished after 20.000000 time steps\n",
      "Episode 665, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998605, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 665 finished after 19.000000 time steps\n",
      "Episode 666, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998608, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 666 finished after 22.000000 time steps\n",
      "Episode 667, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998612, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 667 finished after 22.000000 time steps\n",
      "Episode 668, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998615, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 668 finished after 18.000000 time steps\n",
      "Episode 669, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998619, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 669 finished after 22.000000 time steps\n",
      "Episode 670, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998623, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 670 finished after 18.000000 time steps\n",
      "Episode 671, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998627, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 671 finished after 22.000000 time steps\n",
      "Episode 672, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998630, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 672 finished after 20.000000 time steps\n",
      "Episode 673, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998633, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 673 finished after 16.000000 time steps\n",
      "Episode 674, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998635, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 674 finished after 18.000000 time steps\n",
      "Episode 675, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998639, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 675 finished after 22.000000 time steps\n",
      "Episode 676, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998642, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 676 finished after 16.000000 time steps\n",
      "Episode 677, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998646, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 677 finished after 22.000000 time steps\n",
      "Episode 678, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998650, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 678 finished after 18.000000 time steps\n",
      "Episode 679, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998653, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 679 finished after 16.000000 time steps\n",
      "Episode 680, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998656, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 680 finished after 22.000000 time steps\n",
      "Episode 681, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998660, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 681 finished after 19.000000 time steps\n",
      "Episode 682, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998662, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 682 finished after 20.000000 time steps\n",
      "Episode 683, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998665, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 683 finished after 20.000000 time steps\n",
      "Episode 684, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998669, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 684 finished after 20.000000 time steps\n",
      "Episode 685, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998673, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 685 finished after 22.000000 time steps\n",
      "Episode 686, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998677, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 686 finished after 16.000000 time steps\n",
      "Episode 687, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998681, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 687 finished after 22.000000 time steps\n",
      "Episode 688, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998685, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 688 finished after 18.000000 time steps\n",
      "Episode 689, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998689, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 689 finished after 21.000000 time steps\n",
      "Episode 690, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998693, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 690 finished after 20.000000 time steps\n",
      "Episode 691, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998695, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 691 finished after 21.000000 time steps\n",
      "Episode 692, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998698, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 692 finished after 20.000000 time steps\n",
      "Episode 693, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998701, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 693 finished after 16.000000 time steps\n",
      "Episode 694, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998703, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 694 finished after 20.000000 time steps\n",
      "Episode 695, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998707, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 695 finished after 22.000000 time steps\n",
      "Episode 696, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998711, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 696 finished after 21.000000 time steps\n",
      "Episode 697, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998715, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 697 finished after 20.000000 time steps\n",
      "Episode 698, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998719, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 698 finished after 20.000000 time steps\n",
      "Episode 699, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998722, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 699 finished after 19.000000 time steps\n",
      "Episode 700, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998726, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 700 finished after 20.000000 time steps\n",
      "Episode 701, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998730, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 701 finished after 18.000000 time steps\n",
      "Episode 702, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998734, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 702 finished after 21.000000 time steps\n",
      "Episode 703, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998736, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 703 finished after 16.000000 time steps\n",
      "Episode 704, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998740, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 704 finished after 20.000000 time steps\n",
      "Episode 705, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998743, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 705 finished after 20.000000 time steps\n",
      "Episode 706, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998745, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 706 finished after 20.000000 time steps\n",
      "Episode 707, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998749, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 707 finished after 21.000000 time steps\n",
      "Episode 708, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998752, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 708 finished after 22.000000 time steps\n",
      "Episode 709, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998755, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 709 finished after 21.000000 time steps\n",
      "Episode 710, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998759, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 710 finished after 20.000000 time steps\n",
      "Episode 711, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998763, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 711 finished after 17.000000 time steps\n",
      "Episode 712, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998766, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 712 finished after 22.000000 time steps\n",
      "Episode 713, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998769, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 713 finished after 20.000000 time steps\n",
      "Episode 714, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998773, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 714 finished after 19.000000 time steps\n",
      "Episode 715, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998776, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 715 finished after 20.000000 time steps\n",
      "Episode 716, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998780, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 716 finished after 17.000000 time steps\n",
      "Episode 717, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998782, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 717 finished after 22.000000 time steps\n",
      "Episode 718, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998786, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 718 finished after 20.000000 time steps\n",
      "Episode 719, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998790, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 719 finished after 20.000000 time steps\n",
      "Episode 720, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998793, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 720 finished after 20.000000 time steps\n",
      "Episode 721, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998797, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 721 finished after 20.000000 time steps\n",
      "Episode 722, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998801, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 722 finished after 16.000000 time steps\n",
      "Episode 723, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998804, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 723 finished after 18.000000 time steps\n",
      "Episode 724, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998807, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 724 finished after 20.000000 time steps\n",
      "Episode 725, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998810, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 725 finished after 18.000000 time steps\n",
      "Episode 726, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998812, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 726 finished after 22.000000 time steps\n",
      "Episode 727, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998815, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 727 finished after 22.000000 time steps\n",
      "Episode 728, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998818, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 728 finished after 18.000000 time steps\n",
      "Episode 729, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998822, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 729 finished after 17.000000 time steps\n",
      "Episode 730, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998825, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 730 finished after 22.000000 time steps\n",
      "Episode 731, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998829, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 731 finished after 17.000000 time steps\n",
      "Episode 732, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998832, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 732 finished after 21.000000 time steps\n",
      "Episode 733, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998836, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 733 finished after 19.000000 time steps\n",
      "Episode 734, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998839, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 734 finished after 21.000000 time steps\n",
      "Episode 735, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998843, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 735 finished after 21.000000 time steps\n",
      "Episode 736, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998846, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 736 finished after 16.000000 time steps\n",
      "Episode 737, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998849, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 737 finished after 20.000000 time steps\n",
      "Episode 738, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998851, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 738 finished after 16.000000 time steps\n",
      "Episode 739, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998854, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 739 finished after 21.000000 time steps\n",
      "Episode 740, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998858, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 740 finished after 21.000000 time steps\n",
      "Episode 741, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998860, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 741 finished after 20.000000 time steps\n",
      "Episode 742, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998862, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 742 finished after 22.000000 time steps\n",
      "Episode 743, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998866, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 743 finished after 20.000000 time steps\n",
      "Episode 744, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998869, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 744 finished after 18.000000 time steps\n",
      "Episode 745, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998873, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 745 finished after 17.000000 time steps\n",
      "Episode 746, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998876, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 746 finished after 18.000000 time steps\n",
      "Episode 747, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998879, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 747 finished after 21.000000 time steps\n",
      "Episode 748, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998882, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 748 finished after 20.000000 time steps\n",
      "Episode 749, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998884, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 749 finished after 20.000000 time steps\n",
      "Episode 750, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998887, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 750 finished after 19.000000 time steps\n",
      "Episode 751, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998891, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 751 finished after 22.000000 time steps\n",
      "Episode 752, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998893, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 752 finished after 22.000000 time steps\n",
      "Episode 753, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998896, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 753 finished after 22.000000 time steps\n",
      "Episode 754, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998899, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 754 finished after 19.000000 time steps\n",
      "Episode 755, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998903, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 755 finished after 22.000000 time steps\n",
      "Episode 756, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998905, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 756 finished after 20.000000 time steps\n",
      "Episode 757, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998908, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 757 finished after 18.000000 time steps\n",
      "Episode 758, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998910, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 758 finished after 20.000000 time steps\n",
      "Episode 759, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998914, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 759 finished after 20.000000 time steps\n",
      "Episode 760, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998917, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 760 finished after 22.000000 time steps\n",
      "Episode 761, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998920, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 761 finished after 21.000000 time steps\n",
      "Episode 762, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998922, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 762 finished after 20.000000 time steps\n",
      "Episode 763, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998926, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 763 finished after 18.000000 time steps\n",
      "Episode 764, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998929, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 764 finished after 16.000000 time steps\n",
      "Episode 765, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998931, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 765 finished after 20.000000 time steps\n",
      "Episode 766, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998934, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 766 finished after 19.000000 time steps\n",
      "Episode 767, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998936, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 767 finished after 20.000000 time steps\n",
      "Episode 768, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998939, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 768 finished after 20.000000 time steps\n",
      "Episode 769, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998943, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 769 finished after 18.000000 time steps\n",
      "Episode 770, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998946, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 770 finished after 20.000000 time steps\n",
      "Episode 771, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998949, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 771 finished after 21.000000 time steps\n",
      "Episode 772, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998951, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 772 finished after 22.000000 time steps\n",
      "Episode 773, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998954, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 773 finished after 16.000000 time steps\n",
      "Episode 774, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998957, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 774 finished after 21.000000 time steps\n",
      "Episode 775, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998960, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 775 finished after 16.000000 time steps\n",
      "Episode 776, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998964, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 776 finished after 20.000000 time steps\n",
      "Episode 777, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998967, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 777 finished after 22.000000 time steps\n",
      "Episode 778, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998970, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 778 finished after 22.000000 time steps\n",
      "Episode 779, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998973, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 779 finished after 18.000000 time steps\n",
      "Episode 780, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998976, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 780 finished after 18.000000 time steps\n",
      "Episode 781, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998978, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 781 finished after 22.000000 time steps\n",
      "Episode 782, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998981, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 782 finished after 16.000000 time steps\n",
      "Episode 783, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998983, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 783 finished after 16.000000 time steps\n",
      "Episode 784, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998985, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 784 finished after 16.000000 time steps\n",
      "Episode 785, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998987, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 785 finished after 20.000000 time steps\n",
      "Episode 786, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998990, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 786 finished after 19.000000 time steps\n",
      "Episode 787, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998993, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 787 finished after 19.000000 time steps\n",
      "Episode 788, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998995, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 788 finished after 18.000000 time steps\n",
      "Episode 789, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.998998, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 789 finished after 17.000000 time steps\n",
      "Episode 790, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999001, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 790 finished after 18.000000 time steps\n",
      "Episode 791, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999003, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 791 finished after 16.000000 time steps\n",
      "Episode 792, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999006, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 792 finished after 22.000000 time steps\n",
      "Episode 793, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999009, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 793 finished after 19.000000 time steps\n",
      "Episode 794, t = 23, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999012, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 794 finished after 23.000000 time steps\n",
      "Episode 795, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999014, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 795 finished after 18.000000 time steps\n",
      "Episode 796, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999017, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 796 finished after 22.000000 time steps\n",
      "Episode 797, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999020, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 797 finished after 22.000000 time steps\n",
      "Episode 798, t = 23, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999023, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 798 finished after 23.000000 time steps\n",
      "Episode 799, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999025, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 799 finished after 18.000000 time steps\n",
      "Episode 800, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999027, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 800 finished after 18.000000 time steps\n",
      "Episode 801, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999030, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 801 finished after 20.000000 time steps\n",
      "Episode 802, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999033, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 802 finished after 21.000000 time steps\n",
      "Episode 803, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999035, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 803 finished after 20.000000 time steps\n",
      "Episode 804, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999037, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 804 finished after 20.000000 time steps\n",
      "Episode 805, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999038, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 805 finished after 22.000000 time steps\n",
      "Episode 806, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999040, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 806 finished after 22.000000 time steps\n",
      "Episode 807, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999043, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 807 finished after 19.000000 time steps\n",
      "Episode 808, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999046, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 808 finished after 21.000000 time steps\n",
      "Episode 809, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999049, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 809 finished after 20.000000 time steps\n",
      "Episode 810, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999052, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 810 finished after 22.000000 time steps\n",
      "Episode 811, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999055, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 811 finished after 18.000000 time steps\n",
      "Episode 812, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999057, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 812 finished after 22.000000 time steps\n",
      "Episode 813, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999059, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 813 finished after 21.000000 time steps\n",
      "Episode 814, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999061, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 814 finished after 16.000000 time steps\n",
      "Episode 815, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999064, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 815 finished after 19.000000 time steps\n",
      "Episode 816, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999067, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 816 finished after 22.000000 time steps\n",
      "Episode 817, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999070, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 817 finished after 22.000000 time steps\n",
      "Episode 818, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999072, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 818 finished after 20.000000 time steps\n",
      "Episode 819, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999074, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 819 finished after 20.000000 time steps\n",
      "Episode 820, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999077, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 820 finished after 19.000000 time steps\n",
      "Episode 821, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999080, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 821 finished after 20.000000 time steps\n",
      "Episode 822, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999082, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 822 finished after 20.000000 time steps\n",
      "Episode 823, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999084, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 823 finished after 19.000000 time steps\n",
      "Episode 824, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999085, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 824 finished after 16.000000 time steps\n",
      "Episode 825, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999088, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 825 finished after 22.000000 time steps\n",
      "Episode 826, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999090, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 826 finished after 20.000000 time steps\n",
      "Episode 827, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999093, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 827 finished after 20.000000 time steps\n",
      "Episode 828, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999095, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 828 finished after 21.000000 time steps\n",
      "Episode 829, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999097, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 829 finished after 20.000000 time steps\n",
      "Episode 830, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999100, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 830 finished after 17.000000 time steps\n",
      "Episode 831, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999102, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 831 finished after 20.000000 time steps\n",
      "Episode 832, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999104, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 832 finished after 21.000000 time steps\n",
      "Episode 833, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999107, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 833 finished after 18.000000 time steps\n",
      "Episode 834, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999110, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 834 finished after 22.000000 time steps\n",
      "Episode 835, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999112, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 835 finished after 20.000000 time steps\n",
      "Episode 836, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999114, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 836 finished after 18.000000 time steps\n",
      "Episode 837, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999117, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 837 finished after 19.000000 time steps\n",
      "Episode 838, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999119, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 838 finished after 22.000000 time steps\n",
      "Episode 839, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999121, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 839 finished after 21.000000 time steps\n",
      "Episode 840, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999123, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 840 finished after 21.000000 time steps\n",
      "Episode 841, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999126, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 841 finished after 20.000000 time steps\n",
      "Episode 842, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999128, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 842 finished after 17.000000 time steps\n",
      "Episode 843, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999131, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 843 finished after 16.000000 time steps\n",
      "Episode 844, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999133, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 844 finished after 19.000000 time steps\n",
      "Episode 845, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999135, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 845 finished after 16.000000 time steps\n",
      "Episode 846, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999138, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 846 finished after 22.000000 time steps\n",
      "Episode 847, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999140, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 847 finished after 22.000000 time steps\n",
      "Episode 848, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999142, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 848 finished after 22.000000 time steps\n",
      "Episode 849, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999145, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 849 finished after 16.000000 time steps\n",
      "Episode 850, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999146, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 850 finished after 20.000000 time steps\n",
      "Episode 851, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999148, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 851 finished after 20.000000 time steps\n",
      "Episode 852, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999151, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 852 finished after 16.000000 time steps\n",
      "Episode 853, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999153, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 853 finished after 22.000000 time steps\n",
      "Episode 854, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999156, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 854 finished after 21.000000 time steps\n",
      "Episode 855, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999158, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 855 finished after 19.000000 time steps\n",
      "Episode 856, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999160, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 856 finished after 20.000000 time steps\n",
      "Episode 857, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999162, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 857 finished after 21.000000 time steps\n",
      "Episode 858, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999165, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 858 finished after 21.000000 time steps\n",
      "Episode 859, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999167, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 859 finished after 20.000000 time steps\n",
      "Episode 860, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999168, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 860 finished after 18.000000 time steps\n",
      "Episode 861, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999170, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 861 finished after 20.000000 time steps\n",
      "Episode 862, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999172, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 862 finished after 19.000000 time steps\n",
      "Episode 863, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999174, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 863 finished after 21.000000 time steps\n",
      "Episode 864, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999176, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 864 finished after 20.000000 time steps\n",
      "Episode 865, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999178, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 865 finished after 22.000000 time steps\n",
      "Episode 866, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999181, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 866 finished after 20.000000 time steps\n",
      "Episode 867, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999183, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 867 finished after 20.000000 time steps\n",
      "Episode 868, t = 19, action = 1, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999186, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 868 finished after 19.000000 time steps\n",
      "Episode 869, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999186, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 869 finished after 18.000000 time steps\n",
      "Episode 870, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999188, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 870 finished after 22.000000 time steps\n",
      "Episode 871, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999190, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 871 finished after 17.000000 time steps\n",
      "Episode 872, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999191, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 872 finished after 20.000000 time steps\n",
      "Episode 873, t = 24, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999194, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 873 finished after 24.000000 time steps\n",
      "Episode 874, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999196, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 874 finished after 20.000000 time steps\n",
      "Episode 875, t = 15, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999199, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 875 finished after 15.000000 time steps\n",
      "Episode 876, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999200, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 876 finished after 21.000000 time steps\n",
      "Episode 877, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999202, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 877 finished after 21.000000 time steps\n",
      "Episode 878, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999204, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 878 finished after 20.000000 time steps\n",
      "Episode 879, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999207, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 879 finished after 22.000000 time steps\n",
      "Episode 880, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999208, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 880 finished after 20.000000 time steps\n",
      "Episode 881, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999210, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 881 finished after 20.000000 time steps\n",
      "Episode 882, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999212, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 882 finished after 20.000000 time steps\n",
      "Episode 883, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999214, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 883 finished after 18.000000 time steps\n",
      "Episode 884, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999217, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 884 finished after 21.000000 time steps\n",
      "Episode 885, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999218, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 885 finished after 22.000000 time steps\n",
      "Episode 886, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999221, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 886 finished after 22.000000 time steps\n",
      "Episode 887, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999222, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 887 finished after 20.000000 time steps\n",
      "Episode 888, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999225, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 888 finished after 19.000000 time steps\n",
      "Episode 889, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999226, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 889 finished after 20.000000 time steps\n",
      "Episode 890, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999228, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 890 finished after 20.000000 time steps\n",
      "Episode 891, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999230, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 891 finished after 21.000000 time steps\n",
      "Episode 892, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999232, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 892 finished after 20.000000 time steps\n",
      "Episode 893, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999234, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 893 finished after 18.000000 time steps\n",
      "Episode 894, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999236, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 894 finished after 18.000000 time steps\n",
      "Episode 895, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999238, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 895 finished after 22.000000 time steps\n",
      "Episode 896, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999241, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 896 finished after 21.000000 time steps\n",
      "Episode 897, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999243, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 897 finished after 18.000000 time steps\n",
      "Episode 898, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999245, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 898 finished after 20.000000 time steps\n",
      "Episode 899, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999247, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 899 finished after 20.000000 time steps\n",
      "Episode 900, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999248, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 900 finished after 18.000000 time steps\n",
      "Episode 901, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999250, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 901 finished after 22.000000 time steps\n",
      "Episode 902, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999252, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 902 finished after 22.000000 time steps\n",
      "Episode 903, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999254, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 903 finished after 20.000000 time steps\n",
      "Episode 904, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999256, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 904 finished after 21.000000 time steps\n",
      "Episode 905, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999258, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 905 finished after 20.000000 time steps\n",
      "Episode 906, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999260, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 906 finished after 21.000000 time steps\n",
      "Episode 907, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999262, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 907 finished after 18.000000 time steps\n",
      "Episode 908, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999265, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 908 finished after 16.000000 time steps\n",
      "Episode 909, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999266, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 909 finished after 20.000000 time steps\n",
      "Episode 910, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999268, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 910 finished after 21.000000 time steps\n",
      "Episode 911, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999270, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 911 finished after 21.000000 time steps\n",
      "Episode 912, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999273, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 912 finished after 19.000000 time steps\n",
      "Episode 913, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999275, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 913 finished after 20.000000 time steps\n",
      "Episode 914, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999277, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 914 finished after 20.000000 time steps\n",
      "Episode 915, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999279, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 915 finished after 18.000000 time steps\n",
      "Episode 916, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999281, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 916 finished after 18.000000 time steps\n",
      "Episode 917, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999283, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 917 finished after 21.000000 time steps\n",
      "Episode 918, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999286, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 918 finished after 22.000000 time steps\n",
      "Episode 919, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999287, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 919 finished after 20.000000 time steps\n",
      "Episode 920, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999289, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 920 finished after 20.000000 time steps\n",
      "Episode 921, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999291, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 921 finished after 21.000000 time steps\n",
      "Episode 922, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999293, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 922 finished after 20.000000 time steps\n",
      "Episode 923, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999295, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 923 finished after 19.000000 time steps\n",
      "Episode 924, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999297, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 924 finished after 22.000000 time steps\n",
      "Episode 925, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999299, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 925 finished after 21.000000 time steps\n",
      "Episode 926, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999300, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 926 finished after 16.000000 time steps\n",
      "Episode 927, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999302, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 927 finished after 18.000000 time steps\n",
      "Episode 928, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999304, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 928 finished after 18.000000 time steps\n",
      "Episode 929, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999305, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 929 finished after 20.000000 time steps\n",
      "Episode 930, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999307, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 930 finished after 20.000000 time steps\n",
      "Episode 931, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999308, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 931 finished after 22.000000 time steps\n",
      "Episode 932, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999310, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 932 finished after 19.000000 time steps\n",
      "Episode 933, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999312, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 933 finished after 18.000000 time steps\n",
      "Episode 934, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999314, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 934 finished after 19.000000 time steps\n",
      "Episode 935, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999316, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 935 finished after 18.000000 time steps\n",
      "Episode 936, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999318, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 936 finished after 22.000000 time steps\n",
      "Episode 937, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999320, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 937 finished after 17.000000 time steps\n",
      "Episode 938, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999321, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 938 finished after 20.000000 time steps\n",
      "Episode 939, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999323, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 939 finished after 16.000000 time steps\n",
      "Episode 940, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999325, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 940 finished after 16.000000 time steps\n",
      "Episode 941, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999326, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 941 finished after 20.000000 time steps\n",
      "Episode 942, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999327, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 942 finished after 19.000000 time steps\n",
      "Episode 943, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999329, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 943 finished after 18.000000 time steps\n",
      "Episode 944, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999331, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 944 finished after 22.000000 time steps\n",
      "Episode 945, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999333, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 945 finished after 20.000000 time steps\n",
      "Episode 946, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999335, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 946 finished after 18.000000 time steps\n",
      "Episode 947, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999337, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 947 finished after 18.000000 time steps\n",
      "Episode 948, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999339, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 948 finished after 16.000000 time steps\n",
      "Episode 949, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999340, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 949 finished after 20.000000 time steps\n",
      "Episode 950, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999341, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 950 finished after 18.000000 time steps\n",
      "Episode 951, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999343, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 951 finished after 18.000000 time steps\n",
      "Episode 952, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999345, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 952 finished after 22.000000 time steps\n",
      "Episode 953, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999346, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 953 finished after 20.000000 time steps\n",
      "Episode 954, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999348, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 954 finished after 21.000000 time steps\n",
      "Episode 955, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999350, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 955 finished after 22.000000 time steps\n",
      "Episode 956, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999352, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 956 finished after 20.000000 time steps\n",
      "Episode 957, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999354, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 957 finished after 22.000000 time steps\n",
      "Episode 958, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999356, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 958 finished after 22.000000 time steps\n",
      "Episode 959, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999358, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 959 finished after 22.000000 time steps\n",
      "Episode 960, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999359, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 960 finished after 16.000000 time steps\n",
      "Episode 961, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999360, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 961 finished after 22.000000 time steps\n",
      "Episode 962, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999362, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 962 finished after 18.000000 time steps\n",
      "Episode 963, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999364, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 963 finished after 21.000000 time steps\n",
      "Episode 964, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999366, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 964 finished after 21.000000 time steps\n",
      "Episode 965, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999368, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 965 finished after 18.000000 time steps\n",
      "Episode 966, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999370, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 966 finished after 20.000000 time steps\n",
      "Episode 967, t = 17, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999372, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 967 finished after 17.000000 time steps\n",
      "Episode 968, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999373, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 968 finished after 19.000000 time steps\n",
      "Episode 969, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999375, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 969 finished after 20.000000 time steps\n",
      "Episode 970, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999377, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 970 finished after 20.000000 time steps\n",
      "Episode 971, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999378, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 971 finished after 20.000000 time steps\n",
      "Episode 972, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999380, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 972 finished after 19.000000 time steps\n",
      "Episode 973, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999382, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 973 finished after 18.000000 time steps\n",
      "Episode 974, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999383, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 974 finished after 18.000000 time steps\n",
      "Episode 975, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999385, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 975 finished after 18.000000 time steps\n",
      "Episode 976, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999386, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 976 finished after 20.000000 time steps\n",
      "Episode 977, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999388, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 977 finished after 21.000000 time steps\n",
      "Episode 978, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999390, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 978 finished after 22.000000 time steps\n",
      "Episode 979, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999392, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 979 finished after 22.000000 time steps\n",
      "Episode 980, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999394, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 980 finished after 19.000000 time steps\n",
      "Episode 981, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999396, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 981 finished after 19.000000 time steps\n",
      "Episode 982, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999397, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 982 finished after 16.000000 time steps\n",
      "Episode 983, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999398, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 983 finished after 18.000000 time steps\n",
      "Episode 984, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999400, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 984 finished after 21.000000 time steps\n",
      "Episode 985, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999401, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 985 finished after 19.000000 time steps\n",
      "Episode 986, t = 16, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999402, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 986 finished after 16.000000 time steps\n",
      "Episode 987, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999403, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 987 finished after 20.000000 time steps\n",
      "Episode 988, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999405, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 988 finished after 19.000000 time steps\n",
      "Episode 989, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999407, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 989 finished after 18.000000 time steps\n",
      "Episode 990, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999408, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 990 finished after 18.000000 time steps\n",
      "Episode 991, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999410, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 991 finished after 20.000000 time steps\n",
      "Episode 992, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999412, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 992 finished after 19.000000 time steps\n",
      "Episode 993, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999413, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 993 finished after 21.000000 time steps\n",
      "Episode 994, t = 20, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999415, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 994 finished after 20.000000 time steps\n",
      "Episode 995, t = 22, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999417, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 995 finished after 22.000000 time steps\n",
      "Episode 996, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999419, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 996 finished after 21.000000 time steps\n",
      "Episode 997, t = 19, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999420, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 997 finished after 19.000000 time steps\n",
      "Episode 998, t = 21, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999422, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 998 finished after 21.000000 time steps\n",
      "Episode 999, t = 18, action = 0, state = (0, 0, 4, 2), reward = 1.000000\n",
      "\t BestQ: 99.999424, Explore rate: 0.010000, Learning rate: 0.100000, Streaks: 0\n",
      "Episode 999 finished after 18.000000 time steps\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
